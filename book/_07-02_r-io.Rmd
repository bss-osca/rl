---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r, code = readLines("common.R"), cache = FALSE, include=FALSE}
```

```{r links, child="links.md"}
```

# Importing and exporting data {#mod-r-io}

For doing data driven analytics, you first must __import__ some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. Moreover, after processing data, you often want to export or store some of the results. This module introduces you to different ways of importing and exporting data. 

We are all different and you may like different learning styles compared to others. In the learning path diagram, there may be links to alternative online content. Note this is an alternative to the standard learning path that you may use instead. The learning path may also have extra content, that is not a part of syllabus, you can have a look at. 

```{r, echo=FALSE, out.width="100%", fig.asp=NA, include=TRUE}
g <- create_learning_path(
   url = "https://docs.google.com/spreadsheets/d/1bBe42LHK-bE7CsU9eNBzi_7VNjbmv-Ybr7285pE61jM/edit?usp=sharing", 
   sheet = "r-io", 
   x_legend = 0, y_legend = 4)
render_graph(g, width = 1000)
```

<!-- * [Chapter 5](https://rafalab.github.io/dsbook/importing-data.html) in @dsbook gives an alternative introduction to importing data. -->


## Learning outcomes {#lo-r-io}

By the end of this module, you are expected to be able to:

* Import and export csv files in different formats.
* Import and export data from Excel.
* Import and export data from Google Sheets.
* Write to a text file.
* Save data using R's native format.
* Read and write to a json file.

The learning outcomes relate to the [overall learning goals](#lg-course) number 7 and 13 of the course.

<!-- SOLO increasing: identify · memorize · name · do simple procedure · collect data · -->
<!-- enumerate · describe · interpret · formulate · list · paraphrase · combine · do -->
<!-- algorithms · compare · contrast · explain causes · analyse · relate · derive · -->
<!-- evaluate · apply · argue · theorise · generalise · hypothesise · solve · reflect -->


## CSV files {#r-io-csv}

[CSV files][wiki-csv] contain *comma separated values* (csv) in plain text and are often named using the file suffix `.csv`. Each line of the file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. `,`, `;` or `_`). The CSV file format is not fully standardized. Different delimiters may be used, fields may be surrounded by quotation marks, text may contain escape characters and the encoding of the file may not be known. Despite these problems, CSV files are commonly used since they are easy to exchange and read.

We will use the [readr][tidyverse-readr] package for reading and writing. An overview over the functions can be seen in the [cheatsheet][cheatsheet-readr].


### Reading a CSV file

In general use the following functions

   * `read_csv`: Read a file with delimiter `,`.
   * `read_csv2`: Read a file with delimiter `;`.
   * `read_delim`: Read a file with a delimiter set by you.

#### Reading an unknown CSV file

For importing a CSV file properly, you need to know the delimiter, if the files has headers and the encoding. If you are not sure, you may have a look on the file by opening it in a text editor or try to read some lines:  

```{r}
csv_file <- readr_example("mtcars.csv") # csv file
lines <- read_lines(csv_file, n_max = 3)
lines
cat(lines, sep = "\n")
```
It seems that the delimiter is a `,` and we may try to read the file using `read_csv`:

```{r}
dat <- read_csv(csv_file)
head(dat)
```

CSV files should always be saved using encoding UTF-8. However, sometimes you may have encoding problems when you read a file:

```{r}
csv_file <- system.file("extdata/persons.csv", package = "tfa")
read_csv(csv_file)
```

Note that some of the characters are not converted correctly. This is usually because the file encoding is not UTF-8. In this case, try to guess the encoding using:

```{r}
guess_encoding(csv_file)
dat <- read_csv(csv_file, locale = locale(encoding = "ISO-8859-1"))
dat
```


### Writing to CSV files

Given a tibble/data frame export it using `write_csv`:

```{r}
csv_file <- "testing.csv"
write_csv(dat, file = csv_file) 
write_csv2(dat, file = "testing_semicolon.csv")   # use a semicolon as delimitor
```

You can now always import the data again using `read_csv`:

```{r}
read_csv(csv_file)
guess_encoding(csv_file)
```
Note that `write_csv` always saves the file using encoding UTF-8. 

In a few cases, you may need to save a CSV file that can be read by Excel. For this purpose use:

```{r}
write_excel_csv2(dat, csv_file)
```

The CSV file can now be opened correctly in Excel. 

```{r, include=FALSE}
unlink(c("testing.csv", "testing_semicolon.csv"))
```


## Excel {#r-io-excel}

There are different packages in R for reading and writing to Excel. We will use the [readxl][tidyverse-readxl] package for reading Excel files which is a part of tidyverse. The package supports both the legacy `.xls` format and the modern xml-based `.xlsx` format. Let us use one of the example files provided by the package:

```{r}
xlsx_file <- system.file("extdata/datasets.xlsx", package = "readxl")
```

It is always a good idea to have a look at the file before you import from it. You can open it from R by using: 

```{r, eval=FALSE}
browseURL(xlsx_file)
```

Data can be read using:

```{r}
library(readxl)
xlsx <- read_excel(xlsx_file)   # reads the first sheet
xlsx
xlsx <- read_excel(xlsx_file, sheet = 2)   # reads the second sheet
xlsx
xlsx <- read_excel(xlsx_file, sheet = "quakes")   # reads a named sheet
xlsx
xlsx <- read_excel(xlsx_file, sheet = "mtcars", range = "A5:G11", col_names = F)   # reads a range
colnames(xlsx) <- read_excel(xlsx_file, sheet = "mtcars", range = "A1:G1", col_names = F)   # reads the column names
xlsx
```

Writing to an Excel file can be done using the [openxlsx][pkg-openxlsx] package. To write to a new file use:

```{r, cache=TRUE}
library(openxlsx)
dat <- trees   # test dataset
head(dat)
write.xlsx(dat, "test1.xlsx", sheetName = "trees") # start at cell A1
write.xlsx(dat, "test2.xlsx", sheetName = "trees", startCol = "C", startRow = 3)
```

If you want to append a sheet to a file use:

```{r, cache=TRUE}
xlsx_file <- system.file("extdata/datasets.xlsx", package = "tfa")
file.copy(xlsx_file, "test.xlsx")         # copy the file so can make some tests
wb <- loadWorkbook(file = "test.xlsx")    # read the workbook
addWorksheet(wb = wb, sheetName = "trees")
writeData(wb, sheet = "trees", x = dat)
saveWorkbook(wb, file = "test.xlsx", overwrite = TRUE)
```

```{r, include=FALSE}
unlink(c("test.xlsx", "test1.xlsx", "test2.xlsx"))
```


## Google Sheets {#r-io-google}

You can import and export to Google sheets using the [googlesheets4][tidyverse-googlesheets4] package in tidyverse. To read and write data, in general, you need to be logged in as a Google user. The package will ask you when needed. However, if you only want to read data from a public sheet, you can use `gs4_deauth` to skip this:

```{r, eval=FALSE}
library(googlesheets4)
gs4_deauth()
```

To read data use:

```{r, eval=FALSE}
url <- "https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077"
read_sheet(url)
read_sheet(url, sheet = 3)
range_read(url, sheet = 2, n_max = 3)
range_read(url, range = "Africa!A5:C15")
```

To write data to a new file use:

```{r, eval=FALSE}
gs4_auth()
gs <- gs4_create("test", sheets = c("Sheet 1", "Sheet 2"))
write_sheet(dat, ss = gs)
range_write(gs, dat, sheet = "Sheet 1", range = "C4")
gs4_browse(gs)  # have a look at the file in a browser
```

To see the results, have a look at your Google sheet `test` in your browser.


## Text files {#r-io-text}

You can read and write to plain text files using the [readr][tidyverse-readr] package. However, mostly you want to write to a text file because you want to save some kind of log file when you run your script. Here `sink` is an excellent function to use, since it redirects your R output. To see the output without messages, errors and warnings use:

```{r, error=TRUE, eval=FALSE}
sink(file = "ex1.log", split = TRUE)  # open the file for output
cat("This is a string\n... and on a new line\n\n")
print("This is another string")
head(mtcars)
rep(1, 4)
message("A message.")
warning("A warning.")
rep(3, f)  # a error
cat("\nLast line\n")
sink()  # close the file again
# file.show("ex1.log")   # to view in external viewer
```

Let us have a look at the content of the file (run `cat(read_file("ex1.log"))`):

```{r, comment="", echo=FALSE}
cat(read_file("ex1.log"))
```

Note that messages, errors and warnings are not included in the output. If you want to include it use:

```{r, error=TRUE, eval=FALSE}
zz <- file("ex2.log", open = "wt")
sink(zz, type = "output")   # open the file for output
sink(zz, type = "message")  # open the same file for messages, errors and warnings
cat("This is a string\n... and on a new line\n\n")
print("This is another string")
head(mtcars)
rep(1, 4)
message("A message.")
warning("A warning.")
rep(3, f)  # a error
cat("\nLast line\n")
sink()  # close the file for output
sink()  # close the file for messages, errors and warnings
```

That is, we call sink two times. Let us have a look at the content of the file:

```{r, comment="", echo=FALSE}
cat(read_file("ex2.log"))
```


## R's native binary format {#r-io-r}

In general, we can differ between two main types of data/files. Information is either binary encoded (basically just 0’s and 1’s) or stored as text files. What we have considered so far is storing data in text files. 

Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. Binary file formats cannot be read by humans but allow space-efficient data compression. Furthermore, binary formats may be difficult to read and write using other programs.

As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which is optimized for speed and compression ratios. To save and read an R object use:

```{r}
dat <- list(x = c(2, 5, 6), y = "A string", z = mtcars)
saveRDS(dat, file = "test.rds")
readRDS("test.rds")
```

Note we here have saved a non tabular R object (a list).

```{r, include=FALSE}
unlink("test.rds")
```


## Json {#r-io-json}

[JavaScript Object Notation][wiki-json] (json) is an open standard text file format, and data interchange format, that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and array data types. It can be used to store non tabular data in text format. It is often used for data-exchange in web-apis. 

Let us try to read and write to a json file using the [jsonlite][pkg-jsonlite] package.

```{r}
library(jsonlite)
dat <- list(x = c(2, 5, 6), y = "A string", z = head(mtcars))
write_json(dat, "test.json", pretty = T)
lst <- read_json("test.json", simplifyDataFrame = T, simplifyVector = T)
lst
```

The content of the json file look likes:

```{r, comment="", echo=FALSE}
cat(read_file("test.json"))
```

```{r, include=FALSE}
unlink("test.json")
```


## Recap {#rc-r-io}

* For doing data driven analytics you first must import some data. That is, take data from a database, file, web API etc. and transform it into a data frame/table. 

* CSV files contain delimiter separated values in plain text and are often named using the file suffix `.csv`. 

* Each line of a csv file is a data record. Each record consists of one or more fields, separated by a common delimiter (e.g. `,`, `;` or `_`). 

* The [readxl][tidyverse-readxl] package can be used to read Excel files. 

* Writing to an Excel file can be done using the [openxlsx][pkg-openxlsx] package. 

* You can import and export to Google sheets using the [googlesheets4][tidyverse-googlesheets4] package in tidyverse. 

* Use `sink` to save output of you R script.

* There are two main types of data files. Information is either binary encoded or stored as text files. 

* Text files can be read by humans and computers alike. The great thing about plain text is their simplicity and their ease of use: any programming language can read a plain text file. 

* Text files are good for storing tabular data but lacks type-safety, and has limited precision for numeric values. 

* Binary file formats cannot be read by humans but allow space-efficient data compression. Moreover they can be used to save non tabular data.

* As most other programming languages, R comes with its own binary format. We will focus on the Rds data format which are optimized for speed and compression ratios. 

* Json is an open standard text file format, and data interchange format. It can be used to store non tabular data in text format. It is often used for data-exchange in web-api's. 

You may also have a look at the [slides for this module](https://bss-osca.github.io/tfa/slides/07-02_r-io-slides.html).



## Exercises {#ex-r-io}

`r strExercises`

[Link to the project on RStudio Cloud for this module][r-cloud-mod16]. 

### Exercise (Statistikbanken)

Use the *exercise R markdown template* to solve this exercise (**File > New File > R Markdown...**, select **From template** and then **TFA Exercise**).

You can use the [API](https://api.statbank.dk/console) from [Statistikbanken](https://www.statistikbanken.dk/) to download a lot of data sets. Let us consider airports in Denmark (data set with table id FLYV41):

```{r}
url <- "https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&LUFTHAVN=*&Tid=*&Transport=*"
```

   1) Use `cat(read_lines(url, n_max = 3), sep = "\n")` to have a look at the delimiter used.
   
   
   
```{r, solution=TRUE, eval=FALSE}
url <- 'https://api.statbank.dk/v1/data/FLYV41/CSV?lang=en&LUFTHAVN=*&Tid=*&Transport=*'
dat <- read_csv2(url)
dat
```
   2) Import the csv file.
   
   
   3) Try to retrieve information and get an overview over the data by running:
      ```{r, eval=FALSE}
      library(jsonlite)
      url <- "https://api.statbank.dk/v1/tableinfo/FLYV41?lang=en"
      lst <- read_json(url, simplifyVector = T)
      View(lst)
      ```
      Note the data returned is in json format, so we use `read_json` to read the data into a list.
      
      
```{r, solution=TRUE, eval=FALSE}
info <- function(tab_id) {
   url <- str_c("https://api.statbank.dk/v1/tableinfo/", tab_id, "?lang=en")
   lst <- read_json(url, simplifyVector = T) 
   return(list(description = lst$description, unit = lst$unit, variables = lst$variables[,1:2]))
}
info("FLYV41")
```
```{r, hint=TRUE, eval=FALSE, title = "Hint 2"}
info <- function(tab_id) {
   url <- str_c(___)
   lst <- read_json(___) 
   return(list(description = lst$___, unit = ___, ___))
}
info("FLYV41")
```
```{r, hint=TRUE, eval=FALSE, text = "You can modify the code in Question 3 to return only parts of the list.", title = "Hint 1"}
```
   
   4) Create a function `info(tab_id)` that returns a list with components `description`, `unit` and `variables` from the information for a data set with table id `tab_id`. 
      
   5) Information about all the data sets can be retrieved using:
      ```{r, eval=FALSE}
      url <- "https://api.statbank.dk/v1/tables?lang=en"
      lst <- jsonlite::read_json(url, simplifyVector = T)
      View(lst)
      ```
      Have a look at the row for FLYV41.
   
   

```{r, solution=TRUE, eval=FALSE}
get_data <- function(tab_id, col_id = NULL) {
   url <- str_c("https://api.statbank.dk/v1/tableinfo/", tab_id, "?lang=en")
   lst <- read_json(url, simplifyVector = T) 
   cols <- lst$variables$id
   if (!is.null(col_id)) cols <- cols[col_id]
   url <- str_c("https://api.statbank.dk/v1/data/", tab_id, "/CSV?lang=en&", str_c(cols, collapse = "=*&"), "=*") %>% 
      URLencode()
   dat <- read_csv2(url)
   return(dat)
}
get_data("FLYV41", 3)
get_data("FLYV41", 1:2)
get_data("FLYV41")
```
```{r, hint=TRUE, eval=FALSE}
get_data <- function(tab_id, col_id = NULL) {
   url <- ___
   lst <- ___
   cols <- lst$variables$id
   if (!is.null(col_id)) cols <- cols[___]
   url <- ___
   dat <- ___
   return(dat)
}
get_data("FLYV41", 3)
get_data("FLYV41", 1:2)
get_data("FLYV41")
```
   6) Given the information about variables in a data set we can construct the url to retrieve the data in csv format:
      ```{r}
      tab_id <- "FLYV41"
      url <- str_c("https://api.statbank.dk/v1/tableinfo/", tab_id, "?lang=en")
      lst <- read_json(url, simplifyVector = T) 
      col_id <- c(1,3)  # column ids in lst$variables$id
      cols <- lst$variables$id[col_id]
      url <- str_c("https://api.statbank.dk/v1/data/", tab_id, "/CSV?lang=en&", str_c(cols, collapse = "=*&"), "=*") %>% 
         URLencode()
      url
      ```
      Create a function `get_data(tab_id, col_id)` that retrieve a data set.
      
      
```{r, solution=TRUE, eval=FALSE}
dat <- get_data("FOLK1A", c(2, 3, 5))
dat
write_csv(dat, "test.csv")
```   
   
   7) Use the function `get_data` to retrieve data for `tab_id = "FOLK1A"` and `col_id = c(2, 3, 5)` and save it as a csv file with a comma as delimiter.
   
   
```{r, solution=TRUE, eval=FALSE}
library(openxlsx)
write.xlsx(dat, "test.xlsx", sheetName = "FOLK1A") 

library(googlesheets4)
gs <- gs4_create("test")
write_sheet(dat, ss = gs, sheet = "FOLK1A")
gs4_browse(gs)
``` 
```{r, hint=TRUE, eval=FALSE}
library(openxlsx)
write.xlsx(___) 

library(googlesheets4)
gs <- gs4_create("test")
write_sheet(___, ss = ___, sheet = "FOLK1A")
gs4_browse(gs)
``` 
   8) Save the data in an Excel file and a Google sheet.

### Exercise (tuples in OPL)
   
In the algebraic modeling language OPL (Optimization Programming Language) used by [IBM ILOG CPLEX Optimization Studio](https://www.ibm.com/products/ilog-cplex-optimization-studio), you can define tuples to contain various information. For example consider tuples defined as:

```java
tuple nurse {
  string name;
  int experience;   // higest best
}

tuple shift {
   string departmentName;
   string day;
   int startTime;
   int endTime;
}
```

A `nurse` tuple is then defined as `<"Anne", 11>` and a `shift` tuple as `<"Consultation", "Monday" 12, 18>.

A set of tuples can be defined using:

```java
{nurse} nurses = ...;
{shift} shifts = ...;
```

where the `...` operator means that the sets are read from a data text file:

```java
nurses = {
   <"Anne", 11>, 
   <"Bethanie", 4>, 
   <"Betsy", 2>
};

shifts = {
   <"Emergency", "Monday", 2, 8>,
   <"Emergency", Monday 8 12 4 7>, 
   <"Emergency", "Monday" 12 18 2 5> 
};
```

You can now use the sets to define decision variables $x_{ns}$ equal one if nurse $n$ is assigned to shift $s$. 

In this exercise we will try to generate the data text file given tibbles with data.


```{r, solution=TRUE}
file = "test.dat"
write_lines("nurses = {", file)
write_lines('   <"Anne", 11>', file, append = TRUE)
write_lines('};', file, append = TRUE)
cat(read_file("test.dat"))
```
```{r, hint=TRUE, eval=FALSE}
file = "test.dat"
write_lines("nurses = {", file)
write_lines(___, ___, append = TRUE)
write_lines(___, ___, append = TRUE)
cat(read_file("test.dat"))  # to have a look 
```
1) Try to generate a text file named `test.dat` using function `write_lines` with content 

   ```java 
   nurses = {
      <"Anne", 11>
   };
   ```

Load datasets 

```{r}
# remotes::install_github("bss-osca/tfa/tfa-package", dependencies = FALSE)  # if tfa not installed
library(tfa)
library(tidyverse)
nurses <- read_csv(system.file("extdata/nurses.csv", package = "tfa"))
shifts <- read_csv(system.file("extdata/shifts.csv", package = "tfa"))
```




```{r, solution=TRUE}
nurses %>%
   mutate(across(where(is.character), ~str_c('"', .x, '"'))) 
```
```{r, hint=TRUE, eval=FALSE, title="Hint 2"}
nurses %>%
   mutate(across(where(___), ~str_c('___', .x, '___'))) 
```
```{r, solution=TRUE, title="Hint 1"}
v <- c("foo", "bar")
str_c('"', v, '"')  # use of str_c to add "
str_c(v, collapse = ", ") # collapsing a vector
tbl <- tribble(
   ~name, ~experience,
   "Anne", 11,
   "Bethanie", 4
)
tbl
tbl %>% 
   mutate(across(where(is.character), # use across to find all character columns
                 ~str_c('(', .x, ')'))) # str_c is applied to each column where .x is the column values 
```

2) Transform all character columns in `nurses` so they start and end with `"`. Some hints are given in Hint 1. 


```{r, solution=TRUE}
nurses %>%
   mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
   unite("tuple", everything(), sep = ", ", remove = FALSE)
```
```{r, hint=TRUE, eval=FALSE}
nurses %>%
   mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
   unite("tuple", everything(), sep = ___, remove = ___)
```

3) Unite all columns into a new column named `tuple` where each column is separated with `,`. Hint: have a look at the `unite` function. All columns can be selected using `everything()`.



```{r, solution=TRUE}
nurses %>%
   mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
   unite("tuple", everything(), sep = ", ", remove = FALSE) %>% 
   mutate(tuple = str_c("<", tuple, ">"))
```
```{r, hint=TRUE, eval=FALSE}
nurses %>%
   mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
   unite("tuple", everything(), sep = ", ", remove = FALSE) %>% 
   mutate(tuple = str_c(___, tuple, ___))
```

4) Add `<` and `>` the start and end of the `tuple` column.



```{r, solution=TRUE}
nurses %>%
   mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
   unite("tuple", everything(), sep = ", ", remove = FALSE) %>% 
   mutate(tuple = str_c("<", tuple, ">")) %>% 
   pull(tuple) %>% 
   str_c(collapse = ",\n")
```
```{r, hint=TRUE, eval=FALSE}
nurses %>%
   mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
   unite("tuple", everything(), sep = ", ", remove = FALSE) %>% 
   mutate(tuple = str_c("<", tuple, ">")) %>% 
   pull(___) %>% 
   str_c(___)
```

5) Extract the `tuple` column and transform it into a string with `collapse = ",\n"`.



```{r, solution=TRUE}
write_tuple <- function(dat, file) {
   write_lines("nurses = {", file, sep = "\n   ")
   tuples <- dat %>%
      mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
      unite("tuple", everything(), sep = ", ", remove = FALSE) %>% 
      mutate(tuple = str_c("<", tuple, ">")) %>% 
      pull(tuple) %>% 
      str_c(collapse = ",\n   ")
   write_lines(tuples, file, append = TRUE)
   write_lines("};", file, append = TRUE)
}
file <- "test.dat"
write_tuple(nurses, file)
cat(read_file("test.dat"))  # to have a look 
```
```{r, hint=TRUE, eval=FALSE, title="Hint 2"}
write_tuple <- function(dat, file) {
   write_lines("nurses = {", file, sep = "\n   ")
   tuples <- dat %>%
      ___
   write_lines(tuples, file, append = TRUE)
   write_lines("};", file, append = TRUE)
}
file <- "test.dat"
write_tuple(nurses, file)
cat(read_file("test.dat"))  # to have a look 
```
```{r, hint=TRUE, eval=FALSE, title="Hint 1"}
write_tuple <- function(dat, file) {
   write_lines(___)
   ___
   write_lines("};", ___, ___)
}
file <- "test.dat"
write_tuple(nurses, file)
cat(read_file("test.dat"))  # to have a look 
```

6) Create a function `write_tuple` that takes nurses as input and write the tuples to a file.

The name of an object can be extracted as a string using 

```{r}
deparse(substitute(nurses))
```




```{r, solution=TRUE}
write_tuple <- function(dat, file) {
   name <- deparse(substitute(dat))
   write_lines(str_c(name, " = {"), file, sep = "\n   ")
   tuples <- dat %>%
      mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
      unite("tuple", everything(), sep = ", ", remove = FALSE) %>% 
      mutate(tuple = str_c("<", tuple, ">")) %>% 
      pull(tuple) %>% 
      str_c(collapse = ",\n   ")
   write_lines(tuples, file, append = TRUE)
   write_lines("};", file, append = TRUE)
}
file <- "test.dat"
write_tuple(shifts, file)
cat(read_file("test.dat"))  # to have a look 
```

7) Modify `write_tuple` so it works if `shifts` are given as input instead of nurses.




```{r, solution=TRUE}
write_tuple <- function(dat, file, append = FALSE) {
   name <- deparse(substitute(dat))
   write_lines(str_c("\n", name, " = {"), file, sep = "\n   ", append = append)
   tuples <- dat %>%
      mutate(across(where(is.character), ~str_c('"', .x, '"'))) %>% 
      unite("tuple", everything(), sep = ", ", remove = FALSE) %>% 
      mutate(tuple = str_c("<", tuple, ">")) %>% 
      pull(tuple) %>% 
      str_c(collapse = ",\n   ")
   write_lines(tuples, file, append = TRUE)
   write_lines("};", file, append = TRUE)
}
```

8) Modify `write_tuple` with a new input argument `append` which is false by default. If true, then then the file is not overwritten.




```{r, solution=TRUE}
file <- "test.dat"
write_tuple(nurses, file)
write_tuple(shifts, file, append = TRUE)
cat(read_file("test.dat"))  # to have a look 
```

9) Write `nurses` and `shifts` to a single data file.


```{r, include=FALSE}
unlink("test.dat")
```


