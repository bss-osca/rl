---
title: "RL in action"
author: "Lars Relund Nielsen"
output:
  xaringan::moon_reader:
    css: "./libs/slides.css"
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightLines: true
      highlightStyle: solarized-light
      countIncrementalSlides: false
      slideNumberFormat: ""
editor_options: 
  chunk_output_type: console
---

```{r, child = "setup.Rmd", echo=FALSE}
```

```{r include=FALSE, eval=FALSE}
# to preview
xaringan::inf_mr(cast_from = ".")
```

layout: true
  
```{r, echo=FALSE}
module_name <- "rl-in-action"
module_number <- "03"
here::i_am(str_c("slides/", module_number, "_", module_name, "-slides.Rmd"))
library(htmltools)
footerHtml <- withTags({
   div(class="my-footer",
      span(
         a(href=str_c("https://bss-osca.github.io/rl/sec-", module_name, ".html"), target="_blank", "Notes"), 
         " | ",
         a(href=str_c("https://bss-osca.github.io/rl/slides/", module_number, "_", module_name, "-slides.html"), target="_blank", "Slides"),    
         " | ",
         a(href=str_c("https://github.com/bss-osca/rl/blob/master/slides/", module_number, "_", module_name, "-slides.Rmd"), target="_blank", "Source"),  
      )
   )
})
footerHtml
knitr::opts_chunk$set(fig.path=str_c("img/", module_name, "-"))
```

---

## Learning outcomes 

* Identify the blocks of a RL model (environment, agent, data, states, actions, rewards and policies) on a specific problem.
* Define the value function for the problem.
* Code your first RL algorithm.
* Evaluate on the solution.

---

## Let's play Tic-Tac-Toe

We start with an empty board and have at most 9 moves (a player may win before). The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row wins the game. Reward for a player is 1 for 'win', 0.5 for 'draw', and 0 for 'loss'. These values can be seen as the probability of winning. 

```{r, echo=FALSE}
library(tidyverse)
library(kableExtra)
library(R6)
library(hash)
library(zoo)
library(patchwork)
library(diagram)
```

```{r, message=FALSE, echo=FALSE}
plot_board_state_cat <- function(state) {
   s <- str_split(state, "")[[1]]
   r1 <- str_c("|  ", s[1], "  |  ", s[2], "   |  ", s[3],"  |\n")
   r2 <- str_c("|  ", s[4], "  |  ", s[5], "   |  ", s[6],"  |\n")
   r3 <- str_c("|  ", s[7], "  |  ", s[8], "   |  ", s[9],"  |\n")
   str <- str_c("|------------------|\n", r1, "|------------------|\n", r2, "|------------------|\n", r3, "|------------------|\n")
   return(cat(str))
}

plot_board_state <- function(state) {
   s <- str_split(state, "")[[1]]
   tbl <- matrix(s, nrow = 3, byrow = T)
   tbl <- as_tibble(tbl, .name_repair = "minimal")
   tbl <- tbl %>% 
      kbl(align = "c", col.names = NULL, table.attr = "border: 1px solid black;") %>% 
      kable_styling(full_width = F, bootstrap_options = c("bordered")) 
   return(tbl)
}
```

```{r, message=FALSE, echo=FALSE}
tblW <- plot_board_state("..X.X.XOO")
tblL <- plot_board_state("X.X.X.OOO")
tblD <- plot_board_state("XXOOOXXXO")
```

<table style="width: 100%; border: 0px !important;">
  <tr>
    <td>`r tblW`</td>
    <td>`r tblL`</td>
    <td>`r tblD`</td>
  </tr>
</table>



---

## Gameplay

Let $S_t$ denote the board state before the opponent makes a move.

```{r hgfFunc, include=FALSE}
#' Plot parts of the state expanded hypergraph
#' 
#' A plot is created based on a grid. Each grid point is numbered from bottom to top and next from left to right,
#' i.e. given grid coordinates (row,col) the grid id is (col-1)*rows + (1 + rows - row). 
#' 
#' @param gridDim A 2-dim vector (rows,cols) representing the size of the grid.
#' @param states A data frame containing columns: sId = state id, gId = grid id, label = text and draw = boolean 
#' @param actions A list with mandatory items head = state id, tails = state and voluntary items label, ids, lwd, lty, highlight and col.
#'   if highlight is true then highlight the action (useful if want to show the policy).
#' @param showGrid If true show the grid points (good for debugging).
#' @param radx Node size scaling (same with rady).
#' @param ... Graphical parameters e.g. \code{cex=0.5} to control text size. 
#'   
#' @return NULL
plotHypergraph<-function(gridDim,states=NULL,actions=NULL,showGrid=FALSE, 
                         radx = 0.03, rady=0.07, cex=1, marX=0.035, marY=0.07, ...)
{
   # internal functions
   gMap<-function(sId) return(states$gId[states$sId %in% sId])		# return gId given sId
   sMap<-function(gId) return(states$sId[states$gId %in% gId])		# return sId given gId
   
   pos <- coordinates(rep(gridDim[1], gridDim[2]), hor = F)  # coordinates of each point in the grid
   openplotmat(xlim=c(min(pos[,1])-marX,max(pos[,1])+marX), 
               ylim=c(min(pos[,2])-marY,max(pos[,2])+marY) )  #main = "State expanded hypergraph"
   
   # plot actions
   if (!is.null(actions)) {
      for (i in seq_along(actions)) {
         head <- actions[[i]]$state
         tails <- actions[[i]]$trans
         lwd <- ifelse(is.null(actions[[i]]$lwd), 1, actions[[i]]$lwd)
         lty <- ifelse(is.null(actions[[i]]$lty), 1, actions[[i]]$lty)
         col <- ifelse(is.null(actions[[i]]$col), "black", actions[[i]]$col)
         label <- ifelse(is.null(actions[[i]]$label), "", actions[[i]]$label)
         if (str_length(label) != 0) label <- parse(text = label)
         highlight <- ifelse(is.null(actions[[i]]$highlight), F, actions[[i]]$highlight)
         if (highlight) lwd <- lwd + 1
         pt <- splitarrow(to = pos[gMap(tails), ], from = pos[gMap(head),], lwd=lwd, lty=lty, arr.type = "none",
                        # arr.side = 1, arr.pos = 0.7, arr.type="curved", arr.lwd = 0.5, arr.length = 0.25, arr.width = 0.2, 
                        lcol=col)
         textempty(pt, lab=label, adj=c(2, 1), cex=cex, ...)
      }
   }	
   
   # plot states
   if (!is.null(states)) {
      for (i in 1:length(states$gId)) { 
         label <- ""
         if (str_length(states$label[i]) != 0) label <- parse(text = states$label[i])
         if (states$draw[i]) textellipse(pos[states$gId[i], ], lab = label, radx = radx, rady=rady, shadow.size = 0, lwd=0.5, cex=cex) 
      }
   }
   
   # Plot rewards
   if (!is.null(actions)) {
      for (i in seq_along(actions)) {
         if (!is.null(actions[[i]]$reward)) {
            label <- parse(text = actions[[i]]$reward$label)
            state <- actions[[i]]$reward$state
            textempty(pos[gMap(state), ], lab=label, adj=c(2.1, 0), cex=cex, ...)
         }
      }
   }	
   
   # visual view of the point numbers (for figuring out how to map stateId to gridId)
   if (showGrid) {
      for (i in 1:dim(pos)[1]) textrect(pos[i, ], lab = i, radx = 0.0, cex=cex)
   }
   return(invisible(NULL))
}
```

```{r hgf, echo=FALSE, out.height="80%", fig.width=12}
par(mar=c(0,0,0,0), omi=c(0,0,0,0))
set.seed(567)
stateN <- 9   # states/stage
stages <- 10   # stages
gridDim <- c(stateN, stages)
states <- tibble(sId = 1:(stages * stateN), gId = 1:(stages * stateN), label = "", draw = rep(T, stages * stateN))
path <- c(6, 15, 23, 31, 38, 49, 59, 66, 75, 86)  # using starte ids
states <- states %>% mutate(draw = if_else(sId %in% setdiff(1:9, path[1]), F, T))
states$label[path[seq_along(path) %% 2 == 1]] <- str_c("S[", seq_along(path[seq_along(path) %% 2 == 1])-1, "]")
actions <- list()
addHArc <- function(actions, harc) {
   actions[[length(actions)+1]] <- harc
   return(actions)
}
for (i in 1:(length(path)-1)) {
   turn <- ((i-1) %% 2) == 1
   if (turn) {
      harc <- list(
         state = path[i],
         trans =  path[i + 1]
         # label = str_c("A[", i/2 - 1, "]")
      )
      actions <- addHArc(actions, harc)
      nxt <-
         sample(setdiff((i * stateN + 1):((i + 1) * stateN), path[i + 1]), 9-i)
      for (s in nxt) {
         harc <- list(state = path[i],
                      trans =  s,
                      lty = 2)
         actions <- addHArc(actions, harc)
      }
   }
   else {
      harc <- list(state = path[i],
                   trans =  path[i + 1],
                   col = "grey")
      actions <- addHArc(actions, harc)
   }
}
plotHypergraph(gridDim, states, actions, showGrid = F, cex = 1, radx = 0.02, rady=0.025, marX=0.02, marY=0.07)
```

---

## Learning to play

- Define $V(S)$ to be 1 if we win, 0 if we loose and 0.5 otherwise (reward/pr of winning).
- Most of the time we *exploit* our knowledge with $pr = 1-\epsilon$, i.e. choose the action which gives us the highest estimated reward and update the value of a state using $$V(S_t) = V(S_t) + \alpha(V(S_{t+1})-V(S_t))$$ where $\alpha$ is the *step-size* parameter. 
- Some times we *explore* with $pr = \epsilon$ and choose another action/move than what seems optimal. 

---

## Let us have a look at the code

- Open the [Tic-tac-toe][colab-03-rl-in-action] notebook.



```{r links, child="../book/links.md"}
```

```{r postprocess, include=FALSE}
system2("Rscript", args = "-e 'rmarkdown::render(\"index.Rmd\", quiet = TRUE)'")
file.copy("./slides.css", "./libs/", overwrite = T)
```
