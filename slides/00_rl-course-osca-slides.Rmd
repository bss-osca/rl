---
title: "Reinforcement Learning for Business"
author: "Lars Relund Nielsen"
output:
  xaringan::moon_reader:
    css: "./libs/slides.css"
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightLines: true
      highlightStyle: solarized-light
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r, child = "setup.Rmd", echo=FALSE}
```

```{r include=FALSE, eval=FALSE}
# to preview
xaringan::inf_mr(cast_from = ".")
```

layout: true

---

## Course overview 

- The purpose of this course is to give an introduction and knowledge about reinforcement learning (RL).
- 10 ECTS.
- Lectures/tutorials each week.
- Exercises and a project are given to support your learning.
<!-- - R is used as programming tool.  -->
- 20 minutes oral exam.

<!-- For more information see the [course description](https://kursuskatalog.au.dk/en?search=Reinforcement%20Learning%20for%20Business). -->

---

## What is reinforcement learning

RL can be seen as 

* An approach of modelling sequential decision making problems.
* An approach for learning good decision making under uncertainty from experience.
* Mathematical models for learning-based decision making.
* Trying to optimize decisions in a sequential decision model. That is, making a good sequence of decisions.
* Estimating and finding near optimal decisions of a stochastic process with sequential decision making. 
* A model where given a state of a system, the agent wants to take actions to maximize future reward. Often the agent does not know the underlying setting and, thus, is bound to learn from experience.

---

## Sequential decision problems

Examples with possible actions are:

* Playing backgammon (how to move the checkers).
* Driving a car (left, right, forward, back, break, stop, ...).
* How to invest/maintain a portfolio of stocks (buy, sell, amount).  
* Control an inventory (wait, buy, amount).
* Maintain a spare-part (wait, maintain).
* Robot operations (sort, move, ...)
* Dairy cow treatment/replacement (treat, replace, ...)

Note current decisions have an impact on the future. 

---

## RL and intuition

RL can be seen as a way of modelling intuition. An RL model has specific states, actions and reward structure and our goal as an agent is to find good decisions/actions that maximize the total reward. The agent learn using, for instance:

* totally random trials (in the start),
* sophisticated tactics and superhuman skills (in the end). 

That is, as the agent learn, the reward estimate of a given action becomes better. 

As humans, we often learn by trial and error too:

* Learning to walk (by falling/pain).
* Learning to play (strategy is based on the game rules and what we have experienced works based on previous plays). 

This can also be seen as learning the reward of our actions. 


---

## RL in a Machine Learning framework

.pull-left[
* **Supervised learning:** Given data $(x_i, y_i)$ learn to predict $y$ from $x$, i.e. find $y \approx f(x)$ (e.g. regression).
* **Unsupervised learning:** Given data $(x_i)$ learn patterns using $x$, i.e. find $f(x)$ (e.g. clustering).
<!-- * Often assume that data are independent and identically distributed (iid).  -->
* **RL:** Given state $x$ you take an action and observe the reward $r$ and the new state $x'$.
 - There is no supervisor $y$, only a reward signal $r$.
 - Your goal is to find a policy that optimize the total reward function.
]

.pull-right[


```{r echo=FALSE, out.width="100%", fig.align = "center", fig.cap = str}
str <- str_c("Adopted from ", Citet(bib, "Silver15"), ".") 
knitr::include_graphics("img/rl-ml.png")
```
]

```{r links, child="../book/links.md"}
```

```{r postprocess, include=FALSE}
system2("Rscript", args = "-e 'rmarkdown::render(\"index.Rmd\", quiet = TRUE)'")
file.copy("./slides.css", "./libs/", overwrite = T)
```
