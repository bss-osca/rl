fig:analytics
fig:unnamed-chunk-3
fig:unnamed-chunk-4
fig:unnamed-chunk-6
fig:unnamed-chunk-7
fig:hgf
fig:bandit
fig:bandit-choose
eq:avg
fig:hgf1
eq:vq
eq:bell-state
eq:bell-opt-state-policy
eq:bell-opt-state
fig:simple
eq:bm-pol-eval
fig:policy-eval-alg
eq:pi-det
eq:pi-mark-det
thm:unlabeled-div-1
fig:policy-ite-alg
fig:value-ite-alg
fig:mc-prediction-alg
fig:mc-gpi-es-alg
fig:mc-gpi-on-policy-alg
eq:is-approx
eq:isr
eq:ois
eq:upd
eq:wpd
fig:mc-pred-off-policy-alg
fig:mc-gpi-off-policy-alg
eq:td0
fig:td0-pred-alg
fig:rw-trans
fig:td-sarsa-alg
fig:td-q-learning-alg
eq:bellman-q
mod-rl-intro
mod-rl-intro-lo
textbook-readings
what-is-reinforcement-learning
rl-and-business-analytics
rl-in-different-research-deciplines
rl-and-machine-learning
the-rl-data-stream
states-actions-rewards-and-policies
exploitation-vs-exploration
rl-in-action-tic-tac-toe
players-and-learning-to-play
gameplay
rl-intro-tic-learn
summary
sec-rl-intro-ex
ex-r-intro-self
exercise---symmetries
exercise---greedy-play
exercise---learning-from-exploration
exercise---other-improvements
mod-bandit
learning-outcomes-1
textbook-readings-1
the-k-armed-bandit-problem
estimating-the-value-of-an-action
sec-bandit-step-size
optimistic-initial-values
upper-confidence-bound-action-selection
summary-1
sec-bandit-ex
exercise---advertising
exercise---a-coin-game
mod-mdp-1
learning-outcomes-2
textbook-readings-2
an-mdp-as-a-model-for-the-agent-environment
rewards-and-the-objective-function-goal
summary-2
sec-mdp-1-ex
exercise---sequential-decision-problems
exercise---expected-return
mdp-2-ex-gambler
mdp-1-ex-storage
mod-mdp-2
learning-outcomes-3
textbook-readings-3
policies-and-value-functions
sec-mdp-opt
optimality-vs-approximation
semi-mdps-non-fixed-time-length
summary-3
sec-mdp-2-ex
mdp-2-ex-policy
mdp-2-ex-car
mod-dp
learning-outcomes-4
textbook-readings-4
sec-dp-pe
policy-improvement
policy-iteration
value-iteration
generalized-policy-iteration
summary-4
exercises
exercise---gamblers-problem
exercise---car-rental
mod-mc
learning-outcomes-5
textbook-readings-5
mc-prediction-evaluation
mc-prediction-of-action-values
mc-control-improvement
gpi-with-exploring-starts
gpi-using-epsilon-soft-policies
sec-mc-off-policy
weighted-importance-sampling
off-policy-control-improvement
summary-5
exercises-1
mod-td-pred
learning-outcomes-6
textbook-readings-6
what-is-td-learning
td-prediction
td-prediction-for-action-values
benefits-of-td-methods
exercises-2
sec-td-pred-ex-random
sec-td-pred-off-policy
mod-td-control
learning-outcomes-7
textbook-readings-7
sarsa---on-policy-gpi-using-td
q-learning---off-policy-gpi-using-td
expected-sarsa---gpi-using-td
summary-6
exercises-3
mod-r-setup
groups
coding-convention
commenting-your-code
annotate
help
mod-lg-course
colophon
