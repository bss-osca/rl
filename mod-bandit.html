<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Module 2 Multi-armed bandits | Reinforcement Learning for Business (RL)</title>
  <meta name="description" content="Course notes for ‘Reinforcement Learning for Business’" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Module 2 Multi-armed bandits | Reinforcement Learning for Business (RL)" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://bss-osca.github.io/rl//img/logo.png" />
  <meta property="og:description" content="Course notes for ‘Reinforcement Learning for Business’" />
  <meta name="github-repo" content="bss-osca/rl" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Module 2 Multi-armed bandits | Reinforcement Learning for Business (RL)" />
  
  <meta name="twitter:description" content="Course notes for ‘Reinforcement Learning for Business’" />
  <meta name="twitter:image" content="https://bss-osca.github.io/rl//img/logo.png" />

<meta name="author" content="Lars Relund Nielsen" />


<meta name="date" content="2022-09-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/favicon.ico" type="image/x-icon" />
<link rel="prev" href="mod-rl-intro.html"/>
<link rel="next" href="mod-mdp-1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.23/datatables.js"></script>
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<html>
<head>

<script id="code-folding-options" type="application/json">
  {"initial-state": "hide"}
</script>
   
<script>
  $(document).ready(function() {

  // Section anchors
  $('.section h1, .section h2, .section h3, .section h4, .section h5').each(function() {
    anchor = '#' + $(this).parent().attr('id');
    $(this).addClass("hasAnchor").prepend('<a href="' + anchor + '" class="anchor"></a>');
  });
});

// code folding
document.addEventListener("DOMContentLoaded", function() {
  const languages = ['r', 'python', 'bash', 'sql', 'cpp', 'stan', 'julia', 'foldable'];
  const options = JSON.parse(document.getElementById("code-folding-options").text);
  const show = options["initial-state"] !== "hide";
  Array.from(document.querySelectorAll("pre.sourceCode")).map(function(pre) {
    const classList = pre.classList;
    if (languages.some(x => classList.contains(x))) {
      const div = pre.parentElement;
      const state = show || classList.contains("fold-show") && !classList.contains("fold-hide") ? " open" : "";
      div.outerHTML = `<details${state}><summary></summary>${div.outerHTML}</details>`;
    }
  });
});
</script>

<script src="https://hypothes.is/embed.js" async></script>

<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

</head>
</html>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="img/logo.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About the course notes</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-outcomes"><i class="fa fa-check"></i>Learning outcomes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#purpose-of-the-course"><i class="fa fa-check"></i>Purpose of the course</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-goals-of-the-course"><i class="fa fa-check"></i>Learning goals of the course</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reinforcement-learning-textbook"><i class="fa fa-check"></i>Reinforcement learning textbook</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-organization"><i class="fa fa-check"></i>Course organization</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#programming-software"><i class="fa fa-check"></i>Programming software</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ack"><i class="fa fa-check"></i>Acknowledgements and license</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#sec-intro-ex"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#sec-intro-ex-annotate"><i class="fa fa-check"></i>Exercise - How to annotate</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#sec-intro-ex-templates"><i class="fa fa-check"></i>Exercise - Templates</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Introduction to RL</b></span></li>
<li class="chapter" data-level="1" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html"><i class="fa fa-check"></i><b>1</b> An introduction to RL</a>
<ul>
<li class="chapter" data-level="1.1" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#mod-rl-intro-lo"><i class="fa fa-check"></i><b>1.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="1.2" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#textbook-readings"><i class="fa fa-check"></i><b>1.2</b> Textbook readings</a></li>
<li class="chapter" data-level="1.3" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#what-is-reinforcement-learning"><i class="fa fa-check"></i><b>1.3</b> What is reinforcement learning</a></li>
<li class="chapter" data-level="1.4" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#rl-and-business-analytics"><i class="fa fa-check"></i><b>1.4</b> RL and Business Analytics</a></li>
<li class="chapter" data-level="1.5" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#rl-in-different-research-deciplines"><i class="fa fa-check"></i><b>1.5</b> RL in different research deciplines</a></li>
<li class="chapter" data-level="1.6" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#rl-and-machine-learning"><i class="fa fa-check"></i><b>1.6</b> RL and machine learning</a></li>
<li class="chapter" data-level="1.7" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#the-rl-data-stream"><i class="fa fa-check"></i><b>1.7</b> The RL data-stream</a></li>
<li class="chapter" data-level="1.8" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#states-actions-rewards-and-policies"><i class="fa fa-check"></i><b>1.8</b> States, actions, rewards and policies</a></li>
<li class="chapter" data-level="1.9" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#exploitation-vs-exploration"><i class="fa fa-check"></i><b>1.9</b> Exploitation vs Exploration</a></li>
<li class="chapter" data-level="1.10" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#rl-in-action-tic-tac-toe"><i class="fa fa-check"></i><b>1.10</b> RL in action (Tic-Tac-Toe)</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#players-and-learning-to-play"><i class="fa fa-check"></i><b>1.10.1</b> Players and learning to play</a></li>
<li class="chapter" data-level="1.10.2" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#gameplay"><i class="fa fa-check"></i><b>1.10.2</b> Gameplay</a></li>
<li class="chapter" data-level="1.10.3" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#rl-intro-tic-learn"><i class="fa fa-check"></i><b>1.10.3</b> Learning by a sequence of games</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#summary"><i class="fa fa-check"></i><b>1.11</b> Summary</a></li>
<li class="chapter" data-level="1.12" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#sec-rl-intro-ex"><i class="fa fa-check"></i><b>1.12</b> Exercises</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#ex-r-intro-self"><i class="fa fa-check"></i><b>1.12.1</b> Exercise - Self-Play</a></li>
<li class="chapter" data-level="1.12.2" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#ex-r-intro-sym"><i class="fa fa-check"></i><b>1.12.2</b> Exercise - Symmetries</a></li>
<li class="chapter" data-level="1.12.3" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#ex-r-intro-greedy"><i class="fa fa-check"></i><b>1.12.3</b> Exercise - Greedy Play</a></li>
<li class="chapter" data-level="1.12.4" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#ex-r-intro-exploit"><i class="fa fa-check"></i><b>1.12.4</b> Exercise - Learning from Exploration</a></li>
<li class="chapter" data-level="1.12.5" data-path="mod-rl-intro.html"><a href="mod-rl-intro.html#ex-r-intro-other"><i class="fa fa-check"></i><b>1.12.5</b> Exercise - Other Improvements</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Tabular methods</b></span></li>
<li class="chapter" data-level="2" data-path="mod-bandit.html"><a href="mod-bandit.html"><i class="fa fa-check"></i><b>2</b> Multi-armed bandits</a>
<ul>
<li class="chapter" data-level="2.1" data-path="mod-bandit.html"><a href="mod-bandit.html#learning-outcomes-1"><i class="fa fa-check"></i><b>2.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="2.2" data-path="mod-bandit.html"><a href="mod-bandit.html#textbook-readings-1"><i class="fa fa-check"></i><b>2.2</b> Textbook readings</a></li>
<li class="chapter" data-level="2.3" data-path="mod-bandit.html"><a href="mod-bandit.html#the-k-armed-bandit-problem"><i class="fa fa-check"></i><b>2.3</b> The k-armed bandit problem</a></li>
<li class="chapter" data-level="2.4" data-path="mod-bandit.html"><a href="mod-bandit.html#estimating-the-value-of-an-action"><i class="fa fa-check"></i><b>2.4</b> Estimating the value of an action</a></li>
<li class="chapter" data-level="2.5" data-path="mod-bandit.html"><a href="mod-bandit.html#sec-bandit-step-size"><i class="fa fa-check"></i><b>2.5</b> The role of the step-size</a></li>
<li class="chapter" data-level="2.6" data-path="mod-bandit.html"><a href="mod-bandit.html#optimistic-initial-values"><i class="fa fa-check"></i><b>2.6</b> Optimistic initial values</a></li>
<li class="chapter" data-level="2.7" data-path="mod-bandit.html"><a href="mod-bandit.html#upper-confidence-bound-action-selection"><i class="fa fa-check"></i><b>2.7</b> Upper-Confidence Bound Action Selection</a></li>
<li class="chapter" data-level="2.8" data-path="mod-bandit.html"><a href="mod-bandit.html#summary-1"><i class="fa fa-check"></i><b>2.8</b> Summary</a></li>
<li class="chapter" data-level="2.9" data-path="mod-bandit.html"><a href="mod-bandit.html#sec-bandit-ex"><i class="fa fa-check"></i><b>2.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="mod-bandit.html"><a href="mod-bandit.html#ex-bandit-adv"><i class="fa fa-check"></i><b>2.9.1</b> Exercise - Advertising</a></li>
<li class="chapter" data-level="2.9.2" data-path="mod-bandit.html"><a href="mod-bandit.html#ex-bandit-coin"><i class="fa fa-check"></i><b>2.9.2</b> Exercise - A coin game</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html"><i class="fa fa-check"></i><b>3</b> Markov decision processes (MDPs)</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#learning-outcomes-2"><i class="fa fa-check"></i><b>3.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="3.2" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#textbook-readings-2"><i class="fa fa-check"></i><b>3.2</b> Textbook readings</a></li>
<li class="chapter" data-level="3.3" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#an-mdp-as-a-model-for-the-agent-environment"><i class="fa fa-check"></i><b>3.3</b> An MDP as a model for the agent-environment</a></li>
<li class="chapter" data-level="3.4" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#rewards-and-the-objective-function-goal"><i class="fa fa-check"></i><b>3.4</b> Rewards and the objective function (goal)</a></li>
<li class="chapter" data-level="3.5" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#summary-2"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#sec-mdp-1-ex"><i class="fa fa-check"></i><b>3.6</b> Exercises</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#ex-mdp-1-seq"><i class="fa fa-check"></i><b>3.6.1</b> Exercise - Sequential decision problems</a></li>
<li class="chapter" data-level="3.6.2" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#ex-mdp-1-exp-return"><i class="fa fa-check"></i><b>3.6.2</b> Exercise - Expected return</a></li>
<li class="chapter" data-level="3.6.3" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#ex-mdp-1-gambler"><i class="fa fa-check"></i><b>3.6.3</b> Exercise - Gambler’s problem</a></li>
<li class="chapter" data-level="3.6.4" data-path="mod-mdp-1.html"><a href="mod-mdp-1.html#ex-mdp-1-storage"><i class="fa fa-check"></i><b>3.6.4</b> Exercise - Factory storage</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html"><i class="fa fa-check"></i><b>4</b> Policies and value functions for MDPs</a>
<ul>
<li class="chapter" data-level="4.1" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#learning-outcomes-3"><i class="fa fa-check"></i><b>4.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="4.2" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#textbook-readings-3"><i class="fa fa-check"></i><b>4.2</b> Textbook readings</a></li>
<li class="chapter" data-level="4.3" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#policies-and-value-functions"><i class="fa fa-check"></i><b>4.3</b> Policies and value functions</a></li>
<li class="chapter" data-level="4.4" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#sec-mdp-opt"><i class="fa fa-check"></i><b>4.4</b> Optimal policies and value functions</a></li>
<li class="chapter" data-level="4.5" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#optimality-vs-approximation"><i class="fa fa-check"></i><b>4.5</b> Optimality vs approximation</a></li>
<li class="chapter" data-level="4.6" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#semi-mdps-non-fixed-time-length"><i class="fa fa-check"></i><b>4.6</b> Semi-MDPs (non-fixed time length)</a></li>
<li class="chapter" data-level="4.7" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#summary-3"><i class="fa fa-check"></i><b>4.7</b> Summary</a></li>
<li class="chapter" data-level="4.8" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#sec-mdp-2-ex"><i class="fa fa-check"></i><b>4.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#ex-mdp-2-policy"><i class="fa fa-check"></i><b>4.8.1</b> Exercise - Optimal policy</a></li>
<li class="chapter" data-level="4.8.2" data-path="mod-mdp-2.html"><a href="mod-mdp-2.html#ex-mdp-2-car"><i class="fa fa-check"></i><b>4.8.2</b> Exercise - Car rental</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mod-dp.html"><a href="mod-dp.html"><i class="fa fa-check"></i><b>5</b> Dynamic programming</a>
<ul>
<li class="chapter" data-level="5.1" data-path="mod-dp.html"><a href="mod-dp.html#learning-outcomes-4"><i class="fa fa-check"></i><b>5.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="5.2" data-path="mod-dp.html"><a href="mod-dp.html#textbook-readings-4"><i class="fa fa-check"></i><b>5.2</b> Textbook readings</a></li>
<li class="chapter" data-level="5.3" data-path="mod-dp.html"><a href="mod-dp.html#sec-dp-pe"><i class="fa fa-check"></i><b>5.3</b> Policy evaluation</a></li>
<li class="chapter" data-level="5.4" data-path="mod-dp.html"><a href="mod-dp.html#policy-improvement"><i class="fa fa-check"></i><b>5.4</b> Policy Improvement</a></li>
<li class="chapter" data-level="5.5" data-path="mod-dp.html"><a href="mod-dp.html#policy-iteration"><i class="fa fa-check"></i><b>5.5</b> Policy Iteration</a></li>
<li class="chapter" data-level="5.6" data-path="mod-dp.html"><a href="mod-dp.html#value-iteration"><i class="fa fa-check"></i><b>5.6</b> Value Iteration</a></li>
<li class="chapter" data-level="5.7" data-path="mod-dp.html"><a href="mod-dp.html#generalized-policy-iteration"><i class="fa fa-check"></i><b>5.7</b> Generalized policy iteration</a></li>
<li class="chapter" data-level="5.8" data-path="mod-dp.html"><a href="mod-dp.html#summary-4"><i class="fa fa-check"></i><b>5.8</b> Summary</a></li>
<li class="chapter" data-level="5.9" data-path="mod-dp.html"><a href="mod-dp.html#exercises"><i class="fa fa-check"></i><b>5.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="mod-dp.html"><a href="mod-dp.html#ex-dp-gambler"><i class="fa fa-check"></i><b>5.9.1</b> Exercise - Gambler’s problem</a></li>
<li class="chapter" data-level="5.9.2" data-path="mod-dp.html"><a href="mod-dp.html#ex-dp-rental"><i class="fa fa-check"></i><b>5.9.2</b> Exercise - Car rental</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mod-mc.html"><a href="mod-mc.html"><i class="fa fa-check"></i><b>6</b> Monte Carlo methods for prediction and control</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mod-mc.html"><a href="mod-mc.html#learning-outcomes-5"><i class="fa fa-check"></i><b>6.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="6.2" data-path="mod-mc.html"><a href="mod-mc.html#textbook-readings-5"><i class="fa fa-check"></i><b>6.2</b> Textbook readings</a></li>
<li class="chapter" data-level="6.3" data-path="mod-mc.html"><a href="mod-mc.html#mc-prediction-evaluation"><i class="fa fa-check"></i><b>6.3</b> MC prediction (evaluation)</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="mod-mc.html"><a href="mod-mc.html#mc-prediction-of-action-values"><i class="fa fa-check"></i><b>6.3.1</b> MC prediction of action-values</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="mod-mc.html"><a href="mod-mc.html#mc-control-improvement"><i class="fa fa-check"></i><b>6.4</b> MC control (improvement)</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="mod-mc.html"><a href="mod-mc.html#gpi-with-exploring-starts"><i class="fa fa-check"></i><b>6.4.1</b> GPI with exploring starts</a></li>
<li class="chapter" data-level="6.4.2" data-path="mod-mc.html"><a href="mod-mc.html#gpi-using-epsilon-soft-policies"><i class="fa fa-check"></i><b>6.4.2</b> GPI using <span class="math inline">\(\epsilon\)</span>-soft policies</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="mod-mc.html"><a href="mod-mc.html#sec-mc-off-policy"><i class="fa fa-check"></i><b>6.5</b> Off-policy MC prediction</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="mod-mc.html"><a href="mod-mc.html#weighted-importance-sampling"><i class="fa fa-check"></i><b>6.5.1</b> Weighted importance sampling</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="mod-mc.html"><a href="mod-mc.html#off-policy-control-improvement"><i class="fa fa-check"></i><b>6.6</b> Off-policy control (improvement)</a></li>
<li class="chapter" data-level="6.7" data-path="mod-mc.html"><a href="mod-mc.html#summary-5"><i class="fa fa-check"></i><b>6.7</b> Summary</a></li>
<li class="chapter" data-level="6.8" data-path="mod-mc.html"><a href="mod-mc.html#exercises-1"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mod-td-pred.html"><a href="mod-td-pred.html"><i class="fa fa-check"></i><b>7</b> Temporal difference methods for prediction</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mod-td-pred.html"><a href="mod-td-pred.html#learning-outcomes-6"><i class="fa fa-check"></i><b>7.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="7.2" data-path="mod-td-pred.html"><a href="mod-td-pred.html#textbook-readings-6"><i class="fa fa-check"></i><b>7.2</b> Textbook readings</a></li>
<li class="chapter" data-level="7.3" data-path="mod-td-pred.html"><a href="mod-td-pred.html#what-is-td-learning"><i class="fa fa-check"></i><b>7.3</b> What is TD learning?</a></li>
<li class="chapter" data-level="7.4" data-path="mod-td-pred.html"><a href="mod-td-pred.html#td-prediction"><i class="fa fa-check"></i><b>7.4</b> TD prediction</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mod-td-pred.html"><a href="mod-td-pred.html#td-prediction-for-action-values"><i class="fa fa-check"></i><b>7.4.1</b> TD prediction for action-values</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="mod-td-pred.html"><a href="mod-td-pred.html#benefits-of-td-methods"><i class="fa fa-check"></i><b>7.5</b> Benefits of TD methods</a></li>
<li class="chapter" data-level="7.6" data-path="mod-td-pred.html"><a href="mod-td-pred.html#exercises-2"><i class="fa fa-check"></i><b>7.6</b> Exercises</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="mod-td-pred.html"><a href="mod-td-pred.html#ex-td-pred-random"><i class="fa fa-check"></i><b>7.6.1</b> Exercise - A randow walk</a></li>
<li class="chapter" data-level="7.6.2" data-path="mod-td-pred.html"><a href="mod-td-pred.html#ex-td-pred-off-policy"><i class="fa fa-check"></i><b>7.6.2</b> Exercise - Off-policy TD</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mod-td-control.html"><a href="mod-td-control.html"><i class="fa fa-check"></i><b>8</b> Temporal difference methods for control</a>
<ul>
<li class="chapter" data-level="8.1" data-path="mod-td-control.html"><a href="mod-td-control.html#learning-outcomes-7"><i class="fa fa-check"></i><b>8.1</b> Learning outcomes</a></li>
<li class="chapter" data-level="8.2" data-path="mod-td-control.html"><a href="mod-td-control.html#textbook-readings-7"><i class="fa fa-check"></i><b>8.2</b> Textbook readings</a></li>
<li class="chapter" data-level="8.3" data-path="mod-td-control.html"><a href="mod-td-control.html#sarsa---on-policy-gpi-using-td"><i class="fa fa-check"></i><b>8.3</b> SARSA - On-policy GPI using TD</a></li>
<li class="chapter" data-level="8.4" data-path="mod-td-control.html"><a href="mod-td-control.html#q-learning---off-policy-gpi-using-td"><i class="fa fa-check"></i><b>8.4</b> Q-learning - Off-policy GPI using TD</a></li>
<li class="chapter" data-level="8.5" data-path="mod-td-control.html"><a href="mod-td-control.html#expected-sarsa---gpi-using-td"><i class="fa fa-check"></i><b>8.5</b> Expected SARSA - GPI using TD</a></li>
<li class="chapter" data-level="8.6" data-path="mod-td-control.html"><a href="mod-td-control.html#summary-6"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
<li class="chapter" data-level="8.7" data-path="mod-td-control.html"><a href="mod-td-control.html#exercises-3"><i class="fa fa-check"></i><b>8.7</b> Exercises</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="mod-r-setup.html"><a href="mod-r-setup.html"><i class="fa fa-check"></i><b>A</b> Setting up R</a></li>
<li class="chapter" data-level="B" data-path="groups.html"><a href="groups.html"><i class="fa fa-check"></i><b>B</b> Working in groups</a></li>
<li class="chapter" data-level="C" data-path="coding-convention.html"><a href="coding-convention.html"><i class="fa fa-check"></i><b>C</b> Coding/naming convention</a>
<ul>
<li class="chapter" data-level="C.1" data-path="coding-convention.html"><a href="coding-convention.html#commenting-your-code"><i class="fa fa-check"></i><b>C.1</b> Commenting your code</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="annotate.html"><a href="annotate.html"><i class="fa fa-check"></i><b>D</b> Annotate the course notes</a></li>
<li class="chapter" data-level="E" data-path="help.html"><a href="help.html"><i class="fa fa-check"></i><b>E</b> Getting help</a></li>
<li class="chapter" data-level="F" data-path="mod-lg-course.html"><a href="mod-lg-course.html"><i class="fa fa-check"></i><b>F</b> Learning goals</a></li>
<li class="chapter" data-level="G" data-path="colophon.html"><a href="colophon.html"><i class="fa fa-check"></i><b>G</b> Colophon</a></li>
<li class="divider"></li>
<li><center>
  <a rel="license" href="./index.html#ack">
    License: CC BY-NC-SA<br>
    <i class = "fab fa-creative-commons fa-2x"></i>
    <i class = "fab fa-creative-commons-by fa-2x"></i>
    <i class = "fab fa-creative-commons-nc fa-2x"></i>
    <i class = "fab fa-creative-commons-sa fa-2x"></i>
  </a>
</li></center>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Reinforcement Learning for Business (RL)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mod-bandit" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Module 2</span> Multi-armed bandits<a href="mod-bandit.html#mod-bandit" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This module consider the k-armed bandit problem which is a sequential decision problem with one state and <span class="math inline">\(k\)</span> actions. The problem is used to illustrate different learning methods used in RL.</p>
<p>The module is also the first module in the <em>Tabular methods</em> part of the notes. This part describe almost all the core ideas of reinforcement learning algorithms in their simplest forms where the state and action spaces are small enough for the approximate value functions to be represented as arrays or tables.</p>
<div id="learning-outcomes-1" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Learning outcomes<a href="mod-bandit.html#learning-outcomes-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>By the end of this module, you are expected to:</p>
<ul>
<li>Define a k-armed bandit and understand the nature of the problem.</li>
<li>Define the reward of a action (action-reward).</li>
<li>Describe different methods for estimating the action-reward.</li>
<li>Explain the differences between exploration and exploitation.</li>
<li>Formulate an <span class="math inline">\(\epsilon\)</span>-greedy algorithm for selecting the next action.</li>
<li>Interpret the sample-average (variable step-size) versus exponential recency-weighted average (constant step-size) action-reward estimation.</li>
<li>Argue why we might use a constant stepsize in the case of non-stationarity.</li>
<li>Understand the effect of optimistic initial values.</li>
<li>Formulate an upper confidence bound action selection algorithm.</li>
</ul>
<p>The learning outcomes relate to the <a href="mod-lg-course.html#mod-lg-course">overall learning goals</a> number 1, 3, 6, 9, 10 and 12 of the course.</p>
<!-- SOLO increasing: identify · memorise · name · do simple procedure · collect data · -->
<!-- enumerate · describe · interpret · formulate · list · paraphrase · combine · do -->
<!-- algorithms · compare · contrast · explain causes · analyse · relate · derive · -->
<!-- evaluate · apply · argue · theorise · generalise · hypothesise · solve · reflect -->
</div>
<div id="textbook-readings-1" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Textbook readings<a href="mod-bandit.html#textbook-readings-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For this week, you will need to read Chapter 2 - 2.7 in <span class="citation">Sutton and Barto (<a href="#ref-Sutton18" role="doc-biblioref">2018</a>)</span>. Read it before continuing this module. A summary of the book notation can be seen <a href="https://bss-osca.github.io/rl/sutton-notation.pdf">here</a>.</p>
<div>
Slides for this module can be seen
<a href="https://bss-osca.github.io/rl/slides/02_bandit-slides.html" target="_blank">here.</a>
You do not have to look at them before the lecture!
</div>
</div>
<div id="the-k-armed-bandit-problem" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> The k-armed bandit problem<a href="mod-bandit.html#the-k-armed-bandit-problem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Multi-armed bandits attempt to find the best option among a collection of alternatives by learning through trial and error. The name derives from “one-armed bandit,” a slang term for a slot machine — which is a perfect analogy for how these algorithms work.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bandit"></span>
<img src="img/bandit.png" alt="A 4-armed bandit." width="100%" />
<p class="caption">
Figure 2.1: A 4-armed bandit.
</p>
</div>
<p>Imagine you are facing a wall with <span class="math inline">\(k\)</span> slot machines (see Figure <a href="mod-bandit.html#fig:bandit">2.1</a>), and each one pays out at a different rate. A natural way to figure out how to make the most money (rewards) would be to try each at random for a while (exploration), and start playing the higher paying ones once you have gained some experience (exploitation). That is, from an agent/environment point of view the agent considers a single state <span class="math inline">\(s\)</span> at time <span class="math inline">\(t\)</span> and have to choose among <span class="math inline">\(k\)</span> actions given the environment representing the <span class="math inline">\(k\)</span> bandits. Only the rewards from the <span class="math inline">\(k\)</span> bandits are unknown, but the agent observe samples of the reward of an action and can use this to estimate the expected reward of that action. The objective is to find an optimal policy that maximize the total expected reward. Note since the process only have a single state, this is the same as finding an optimal policy <span class="math inline">\(\pi^*(s) = \pi^* = a^*\)</span> that chooses the action with the highest expected reward. Due to uncertainty, there is an exploration vs exploitation dilemma. The agent have one action that seems to be most valuable at a time point, but it is highly likely, at least initially, that there are actions yet to explore that are more valuable.</p>
<!-- For finding the optimal action a learning strategy that balance the exploration vs. exploitation trade-off. -->
<!-- To summarize: -->
<!-- * The agent are faced repeatedly with a choice of $k$ actions. -->
<!-- * After each choice, you receive a reward from a stationary probability distribution. -->
<!-- * Objective is to maximise total reward over some time period, say 100 time steps. -->
<!-- * Each action has an expected or mean reward based on its probability distribution. We shall call thjs the \textit{value} of the action. We do not know these values with certainty. -->
<!-- * Because of this uncertainty, there is always an exploration vs exploitation problem. We always have one action that we deem to be most valuable at any instant, but it is highly likely, at least initially, that there are actions we are yet to explore that are more valuable. -->
<p>Multi-armed bandits can be used in e.g. <a href="https://research.facebook.com/blog/2021/4/auto-placement-of-ad-campaigns-using-multi-armed-bandits/">digital advertising</a>. Suppose you are an advertiser seeking to optimize which ads (<span class="math inline">\(k\)</span> to choose among) to show visitors on a particular website. For each visitor, you can choose one out of a collection of ads, and your goal is to maximize the number of clicks over time.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bandit-choose"></span>
<img src="img/bandit-choose.png" alt="Which ad to choose?" width="100%" />
<p class="caption">
Figure 2.2: Which ad to choose?
</p>
</div>
<p>It is reasonable to assume that each of these ads will have different effects, and some will be more engaging than others. That is, each ad has some theoretical — but unknown — click-through-rate (CTR) that is assumed to not change over time. How do we go about solving which ad we should choose (see Figure <a href="mod-bandit.html#fig:bandit-choose">2.2</a>)?</p>
</div>
<div id="estimating-the-value-of-an-action" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Estimating the value of an action<a href="mod-bandit.html#estimating-the-value-of-an-action" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>How can the value of an action be estimated, i.e. the expected reward of an action <span class="math inline">\(q_*(a) = \mathbb{E}[R_t | A_t = a]\)</span>. Assume that at time <span class="math inline">\(t\)</span> action <span class="math inline">\(a\)</span> has been chosen <span class="math inline">\(N_t(a)\)</span> times. Then the estimated action value is
<span class="math display">\[\begin{equation} 
    Q_t(a) = \frac{R_1+R_2+\cdots+R_{N_t(a)}}{N_t(a)},
\end{equation}\]</span>
Storing <span class="math inline">\(Q_t(a)\)</span> this way is cumbersome since memory and computation requirements grow over time. Instead an <em>incremental</em> approach is better. If we assume that <span class="math inline">\(N_t(a) = n-1\)</span> and set <span class="math inline">\(Q_t(a) = Q_n\)</span> then <span class="math inline">\(Q_{n+1}\)</span> becomes:
<span class="math display" id="eq:avg">\[\begin{align}
  Q_{n+1} &amp;= \frac{1}{n}\sum_{i=1}^{n}R_i \nonumber \\
            &amp;= \frac{1}{n}\left( R_{n} + \sum_{i=1}^{n-1} R_i \right) \nonumber \\
            &amp;= \frac{1}{n}\left( R_{n} + (n-1)\frac{1}{n-1}\sum_{i=1}^{n-1} R_i \right) \nonumber \\
            &amp;= \frac{1}{n}\left( R_{n} + (n-1)Q_n \right) \nonumber \\
           &amp;= Q_n + \frac{1}{n} \left[R_n - Q_n\right].
  \tag{2.1}
\end{align}\]</span>
That is, we can update the estimate of the value of <span class="math inline">\(a\)</span> using the previous estimate, the observed reward and how many times the action has occurred (<span class="math inline">\(n\)</span>).</p>
<p>A greedy approach for selecting the next action is
<span class="math display">\[\begin{equation}
A_t =\arg \max_a Q_t(a).
\end{equation}\]</span>
Here <span class="math inline">\(\arg\max_a\)</span> means the value of <span class="math inline">\(a\)</span> for which <span class="math inline">\(Q_t(a)\)</span> is maximised. A pure greedy approach do not explore other actions. Instead an <span class="math inline">\(\varepsilon\)</span>-greedy approach is used in which with probability <span class="math inline">\(\varepsilon\)</span> we take a random draw from all of the actions (choosing each action with equal probability) and hereby providing some exploration.</p>
<!-- \begin{itemize} -->
<!--    \item Simplest action selection rule is to select the action with the highest estimated value. -->
<!--    \item \(\epsilon\)-greedy methods are where the agent selects the greedy option most of the time, and selects a random action with probability \(\epsilon\). -->
<!--    \item Three algorithms are tried: one with \(e\)=0 (pure greedy), one with \(e\)=0.01 and another with \(e\)=0.1 -->
<!--    \item Greedy method gets stuck performing sub-optimal actions. -->
<!--    \item \(e\)=0.1 explores more and usually finds the optimal action earlier, but never selects it more that 91\% of the time. -->
<!--    \item \(e\)=0.01 method improves more slowly, but eventually performs better than the e=0.1 method on both performance measures. -->
<!--    \item It is possible to reduce \(e\) over time to try to get the best of both high and low values. -->
<!-- \end{itemize} -->
<!-- Note this is the general formula  -->
<!-- \begin{equation} -->
<!-- NewEstimate \leftarrow OldEstimate + StepSize \left[Target - OldEstimate \right] -->
<!-- \end{equation} -->
<p>Let us try to implement the algorithm using an agent and environment class. First we define the agent that do actions based on an <span class="math inline">\(\epsilon\)</span>-greedy strategy, stores the estimated <span class="math inline">\(Q\)</span> values and the number of times an action has been chosen:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="mod-bandit.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; R6 Class representing the RL agent</span></span>
<span id="cb13-2"><a href="mod-bandit.html#cb13-2" aria-hidden="true" tabindex="-1"></a>RLAgent <span class="ot">&lt;-</span> <span class="fu">R6Class</span>(<span class="st">&quot;RLAgent&quot;</span>,</span>
<span id="cb13-3"><a href="mod-bandit.html#cb13-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">public =</span> <span class="fu">list</span>(</span>
<span id="cb13-4"><a href="mod-bandit.html#cb13-4" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field qV Q estimates.</span></span>
<span id="cb13-5"><a href="mod-bandit.html#cb13-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">qV =</span> <span class="cn">NULL</span>,  </span>
<span id="cb13-6"><a href="mod-bandit.html#cb13-6" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-7"><a href="mod-bandit.html#cb13-7" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field nV Action counter.</span></span>
<span id="cb13-8"><a href="mod-bandit.html#cb13-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">nV =</span> <span class="cn">NULL</span>,  </span>
<span id="cb13-9"><a href="mod-bandit.html#cb13-9" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-10"><a href="mod-bandit.html#cb13-10" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field k Number of bandits.</span></span>
<span id="cb13-11"><a href="mod-bandit.html#cb13-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">k =</span> <span class="cn">NULL</span>,   </span>
<span id="cb13-12"><a href="mod-bandit.html#cb13-12" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-13"><a href="mod-bandit.html#cb13-13" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field epsilon Epsilon used in epsilon greed action selection.</span></span>
<span id="cb13-14"><a href="mod-bandit.html#cb13-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">epsilon =</span> <span class="cn">NULL</span>, </span>
<span id="cb13-15"><a href="mod-bandit.html#cb13-15" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-16"><a href="mod-bandit.html#cb13-16" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Create an object (when call new).</span></span>
<span id="cb13-17"><a href="mod-bandit.html#cb13-17" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param k Number of bandits.</span></span>
<span id="cb13-18"><a href="mod-bandit.html#cb13-18" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param epsilon Epsilon used in epsilon greed action selection.</span></span>
<span id="cb13-19"><a href="mod-bandit.html#cb13-19" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return The new object.</span></span>
<span id="cb13-20"><a href="mod-bandit.html#cb13-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">initialize =</span> <span class="cf">function</span>(<span class="at">k =</span> <span class="dv">10</span>, <span class="at">epsilon =</span> <span class="fl">0.01</span>, <span class="at">ini =</span>  <span class="dv">0</span>) {</span>
<span id="cb13-21"><a href="mod-bandit.html#cb13-21" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>epsilon <span class="ot">&lt;-</span> epsilon</span>
<span id="cb13-22"><a href="mod-bandit.html#cb13-22" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>qV <span class="ot">&lt;-</span> <span class="fu">rep</span>(ini, k)</span>
<span id="cb13-23"><a href="mod-bandit.html#cb13-23" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>nV <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k)</span>
<span id="cb13-24"><a href="mod-bandit.html#cb13-24" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>k <span class="ot">&lt;-</span> k</span>
<span id="cb13-25"><a href="mod-bandit.html#cb13-25" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb13-26"><a href="mod-bandit.html#cb13-26" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-27"><a href="mod-bandit.html#cb13-27" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Clear learning.</span></span>
<span id="cb13-28"><a href="mod-bandit.html#cb13-28" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param eps Epsilon.</span></span>
<span id="cb13-29"><a href="mod-bandit.html#cb13-29" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return Action (index).</span></span>
<span id="cb13-30"><a href="mod-bandit.html#cb13-30" aria-hidden="true" tabindex="-1"></a>      <span class="at">clearLearning =</span> <span class="cf">function</span>() {</span>
<span id="cb13-31"><a href="mod-bandit.html#cb13-31" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>qV <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb13-32"><a href="mod-bandit.html#cb13-32" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>nV <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb13-33"><a href="mod-bandit.html#cb13-33" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb13-34"><a href="mod-bandit.html#cb13-34" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-35"><a href="mod-bandit.html#cb13-35" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Select next action using an epsilon greedy strategy.</span></span>
<span id="cb13-36"><a href="mod-bandit.html#cb13-36" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return Action (index).</span></span>
<span id="cb13-37"><a href="mod-bandit.html#cb13-37" aria-hidden="true" tabindex="-1"></a>      <span class="at">selectActionEG =</span> <span class="cf">function</span>() {   </span>
<span id="cb13-38"><a href="mod-bandit.html#cb13-38" aria-hidden="true" tabindex="-1"></a>         <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;=</span> self<span class="sc">$</span>epsilon) { <span class="co"># explore</span></span>
<span id="cb13-39"><a href="mod-bandit.html#cb13-39" aria-hidden="true" tabindex="-1"></a>            a <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>self<span class="sc">$</span>k, <span class="dv">1</span>)</span>
<span id="cb13-40"><a href="mod-bandit.html#cb13-40" aria-hidden="true" tabindex="-1"></a>         } <span class="cf">else</span> { <span class="co"># exploit</span></span>
<span id="cb13-41"><a href="mod-bandit.html#cb13-41" aria-hidden="true" tabindex="-1"></a>            a <span class="ot">&lt;-</span> <span class="fu">which</span>(self<span class="sc">$</span>qV <span class="sc">==</span> <span class="fu">max</span>(self<span class="sc">$</span>qV))</span>
<span id="cb13-42"><a href="mod-bandit.html#cb13-42" aria-hidden="true" tabindex="-1"></a>            a <span class="ot">&lt;-</span> a[<span class="fu">sample</span>(<span class="fu">length</span>(a), <span class="dv">1</span>)]  <span class="co"># choose a action random if more than one</span></span>
<span id="cb13-43"><a href="mod-bandit.html#cb13-43" aria-hidden="true" tabindex="-1"></a>         }</span>
<span id="cb13-44"><a href="mod-bandit.html#cb13-44" aria-hidden="true" tabindex="-1"></a>         <span class="fu">return</span>(a)</span>
<span id="cb13-45"><a href="mod-bandit.html#cb13-45" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb13-46"><a href="mod-bandit.html#cb13-46" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-47"><a href="mod-bandit.html#cb13-47" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Update learning values (including action counter).</span></span>
<span id="cb13-48"><a href="mod-bandit.html#cb13-48" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param a Action.</span></span>
<span id="cb13-49"><a href="mod-bandit.html#cb13-49" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param r Reward.</span></span>
<span id="cb13-50"><a href="mod-bandit.html#cb13-50" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return NULL (invisible)</span></span>
<span id="cb13-51"><a href="mod-bandit.html#cb13-51" aria-hidden="true" tabindex="-1"></a>      <span class="at">updateQ =</span> <span class="cf">function</span>(a, r) {</span>
<span id="cb13-52"><a href="mod-bandit.html#cb13-52" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>nV[a] <span class="ot">&lt;-</span> self<span class="sc">$</span>nV[a] <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb13-53"><a href="mod-bandit.html#cb13-53" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>qV[a] <span class="ot">&lt;-</span> self<span class="sc">$</span>qV[a] <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>self<span class="sc">$</span>nV[a] <span class="sc">*</span> (r <span class="sc">-</span> self<span class="sc">$</span>qV[a])</span>
<span id="cb13-54"><a href="mod-bandit.html#cb13-54" aria-hidden="true" tabindex="-1"></a>         <span class="fu">return</span>(<span class="fu">invisible</span>(<span class="cn">NULL</span>))</span>
<span id="cb13-55"><a href="mod-bandit.html#cb13-55" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb13-56"><a href="mod-bandit.html#cb13-56" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb13-57"><a href="mod-bandit.html#cb13-57" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Next, the environment generating rewards. The true mean reward <span class="math inline">\(q_*(a)\)</span> of an action is selected according to a normal (Gaussian) distribution with mean 0 and variance 1. The observed reward is then generated using a normal distribution with mean <span class="math inline">\(q_*(a)\)</span> and variance 1:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="mod-bandit.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; R6 Class representing the RL environment</span></span>
<span id="cb14-2"><a href="mod-bandit.html#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; </span></span>
<span id="cb14-3"><a href="mod-bandit.html#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; Assume that bandits are normal distributed with a mean and std.dev of one. </span></span>
<span id="cb14-4"><a href="mod-bandit.html#cb14-4" aria-hidden="true" tabindex="-1"></a>RLEnvironment <span class="ot">&lt;-</span> <span class="fu">R6Class</span>(<span class="st">&quot;RLEnvironment&quot;</span>,</span>
<span id="cb14-5"><a href="mod-bandit.html#cb14-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">public =</span> <span class="fu">list</span>(</span>
<span id="cb14-6"><a href="mod-bandit.html#cb14-6" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field mV Mean values</span></span>
<span id="cb14-7"><a href="mod-bandit.html#cb14-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">mV =</span> <span class="cn">NULL</span>,  </span>
<span id="cb14-8"><a href="mod-bandit.html#cb14-8" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb14-9"><a href="mod-bandit.html#cb14-9" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field k Number of bandits.</span></span>
<span id="cb14-10"><a href="mod-bandit.html#cb14-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">k =</span> <span class="cn">NULL</span>,   </span>
<span id="cb14-11"><a href="mod-bandit.html#cb14-11" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb14-12"><a href="mod-bandit.html#cb14-12" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Create an object (when call new).</span></span>
<span id="cb14-13"><a href="mod-bandit.html#cb14-13" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param k Number of bandits.</span></span>
<span id="cb14-14"><a href="mod-bandit.html#cb14-14" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return The new object.</span></span>
<span id="cb14-15"><a href="mod-bandit.html#cb14-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">initialize =</span> <span class="cf">function</span>(<span class="at">k =</span> <span class="dv">10</span>) {</span>
<span id="cb14-16"><a href="mod-bandit.html#cb14-16" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>mV <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(k)</span>
<span id="cb14-17"><a href="mod-bandit.html#cb14-17" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb14-18"><a href="mod-bandit.html#cb14-18" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb14-19"><a href="mod-bandit.html#cb14-19" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Sample reward of a bandit.</span></span>
<span id="cb14-20"><a href="mod-bandit.html#cb14-20" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param a Bandit (index).</span></span>
<span id="cb14-21"><a href="mod-bandit.html#cb14-21" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return The reward.</span></span>
<span id="cb14-22"><a href="mod-bandit.html#cb14-22" aria-hidden="true" tabindex="-1"></a>      <span class="at">reward =</span> <span class="cf">function</span>(a) {</span>
<span id="cb14-23"><a href="mod-bandit.html#cb14-23" aria-hidden="true" tabindex="-1"></a>         <span class="fu">return</span>(<span class="fu">rnorm</span>(<span class="dv">1</span>, self<span class="sc">$</span>mV[a]))</span>
<span id="cb14-24"><a href="mod-bandit.html#cb14-24" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb14-25"><a href="mod-bandit.html#cb14-25" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb14-26"><a href="mod-bandit.html#cb14-26" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Returns action with best mean.</span></span>
<span id="cb14-27"><a href="mod-bandit.html#cb14-27" aria-hidden="true" tabindex="-1"></a>      <span class="at">optimalAction =</span> <span class="cf">function</span>() <span class="fu">return</span>(<span class="fu">which.max</span>(self<span class="sc">$</span>mV))</span>
<span id="cb14-28"><a href="mod-bandit.html#cb14-28" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb14-29"><a href="mod-bandit.html#cb14-29" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>To test the RL algorithm we use a function returning two plots that compare the performance:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="mod-bandit.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; Performance of the bandit algorithm using different epsilons.</span></span>
<span id="cb15-2"><a href="mod-bandit.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39;</span></span>
<span id="cb15-3"><a href="mod-bandit.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @param k Bandits.</span></span>
<span id="cb15-4"><a href="mod-bandit.html#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @param steps Time steps.</span></span>
<span id="cb15-5"><a href="mod-bandit.html#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @param runs Number of runs with a new environment generated.</span></span>
<span id="cb15-6"><a href="mod-bandit.html#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @param epsilons Epsilons to be tested.</span></span>
<span id="cb15-7"><a href="mod-bandit.html#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @param ini Initial value estimates.</span></span>
<span id="cb15-8"><a href="mod-bandit.html#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @return Two plots in a list.</span></span>
<span id="cb15-9"><a href="mod-bandit.html#cb15-9" aria-hidden="true" tabindex="-1"></a>performance <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">k =</span> <span class="dv">10</span>, <span class="at">steps =</span> <span class="dv">1000</span>, <span class="at">runs =</span> <span class="dv">500</span>, </span>
<span id="cb15-10"><a href="mod-bandit.html#cb15-10" aria-hidden="true" tabindex="-1"></a>                        <span class="at">epsilons =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>), <span class="at">ini =</span> <span class="dv">0</span>) {</span>
<span id="cb15-11"><a href="mod-bandit.html#cb15-11" aria-hidden="true" tabindex="-1"></a>   rew <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> steps, <span class="at">ncol =</span> <span class="fu">length</span>(epsilons))   <span class="co"># rewards (one col for each eps)</span></span>
<span id="cb15-12"><a href="mod-bandit.html#cb15-12" aria-hidden="true" tabindex="-1"></a>   best <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> steps, <span class="at">ncol =</span> <span class="fu">length</span>(epsilons))  <span class="co"># add 1 if find the best action</span></span>
<span id="cb15-13"><a href="mod-bandit.html#cb15-13" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> (run <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>runs) {</span>
<span id="cb15-14"><a href="mod-bandit.html#cb15-14" aria-hidden="true" tabindex="-1"></a>      env <span class="ot">&lt;-</span> RLEnvironment<span class="sc">$</span><span class="fu">new</span>(k)</span>
<span id="cb15-15"><a href="mod-bandit.html#cb15-15" aria-hidden="true" tabindex="-1"></a>      oA <span class="ot">&lt;-</span> env<span class="sc">$</span><span class="fu">optimalAction</span>()</span>
<span id="cb15-16"><a href="mod-bandit.html#cb15-16" aria-hidden="true" tabindex="-1"></a>      <span class="co"># print(oA); print(env$mV)</span></span>
<span id="cb15-17"><a href="mod-bandit.html#cb15-17" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(epsilons)) {</span>
<span id="cb15-18"><a href="mod-bandit.html#cb15-18" aria-hidden="true" tabindex="-1"></a>         agent <span class="ot">&lt;-</span> RLAgent<span class="sc">$</span><span class="fu">new</span>(k, epsilons[i], ini)</span>
<span id="cb15-19"><a href="mod-bandit.html#cb15-19" aria-hidden="true" tabindex="-1"></a>         <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps) {</span>
<span id="cb15-20"><a href="mod-bandit.html#cb15-20" aria-hidden="true" tabindex="-1"></a>            a <span class="ot">&lt;-</span> agent<span class="sc">$</span><span class="fu">selectActionEG</span>()</span>
<span id="cb15-21"><a href="mod-bandit.html#cb15-21" aria-hidden="true" tabindex="-1"></a>            r <span class="ot">&lt;-</span> env<span class="sc">$</span><span class="fu">reward</span>(a)</span>
<span id="cb15-22"><a href="mod-bandit.html#cb15-22" aria-hidden="true" tabindex="-1"></a>            agent<span class="sc">$</span><span class="fu">updateQ</span>(a, r)</span>
<span id="cb15-23"><a href="mod-bandit.html#cb15-23" aria-hidden="true" tabindex="-1"></a>            rew[t, i] <span class="ot">&lt;-</span> rew[t, i] <span class="sc">+</span> r  <span class="co"># sum of rewards generated at t</span></span>
<span id="cb15-24"><a href="mod-bandit.html#cb15-24" aria-hidden="true" tabindex="-1"></a>            best[t, i] <span class="ot">&lt;-</span> best[t, i] <span class="sc">+</span> (a <span class="sc">==</span> oA) <span class="co"># times find best actions</span></span>
<span id="cb15-25"><a href="mod-bandit.html#cb15-25" aria-hidden="true" tabindex="-1"></a>         }</span>
<span id="cb15-26"><a href="mod-bandit.html#cb15-26" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb15-27"><a href="mod-bandit.html#cb15-27" aria-hidden="true" tabindex="-1"></a>   }</span>
<span id="cb15-28"><a href="mod-bandit.html#cb15-28" aria-hidden="true" tabindex="-1"></a>   <span class="fu">colnames</span>(rew) <span class="ot">&lt;-</span> epsilons</span>
<span id="cb15-29"><a href="mod-bandit.html#cb15-29" aria-hidden="true" tabindex="-1"></a>   <span class="fu">colnames</span>(best) <span class="ot">&lt;-</span> epsilons</span>
<span id="cb15-30"><a href="mod-bandit.html#cb15-30" aria-hidden="true" tabindex="-1"></a>   dat1 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">t =</span> <span class="dv">1</span><span class="sc">:</span>steps) <span class="sc">%&gt;%</span></span>
<span id="cb15-31"><a href="mod-bandit.html#cb15-31" aria-hidden="true" tabindex="-1"></a>      <span class="fu">bind_cols</span>(rew) <span class="sc">%&gt;%</span>   <span class="co"># bind data together</span></span>
<span id="cb15-32"><a href="mod-bandit.html#cb15-32" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_longer</span>(<span class="sc">!</span>t, <span class="at">values_to =</span> <span class="st">&quot;reward&quot;</span>, <span class="at">names_to =</span> <span class="st">&quot;epsilon&quot;</span>) <span class="sc">%&gt;%</span>   <span class="co"># move rewards to a single column</span></span>
<span id="cb15-33"><a href="mod-bandit.html#cb15-33" aria-hidden="true" tabindex="-1"></a>      <span class="fu">group_by</span>(epsilon) <span class="sc">%&gt;%</span> </span>
<span id="cb15-34"><a href="mod-bandit.html#cb15-34" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">All =</span> <span class="fu">cumsum</span>(reward<span class="sc">/</span>runs)<span class="sc">/</span>t, <span class="st">`</span><span class="at">Moving avg (50)</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rollapply</span>(reward<span class="sc">/</span>runs, <span class="dv">50</span>, mean, <span class="at">align =</span> <span class="st">&quot;right&quot;</span>, <span class="at">fill =</span> <span class="cn">NA</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb15-35"><a href="mod-bandit.html#cb15-35" aria-hidden="true" tabindex="-1"></a>      <span class="fu">select</span>(<span class="sc">-</span>reward) <span class="sc">%&gt;%</span> </span>
<span id="cb15-36"><a href="mod-bandit.html#cb15-36" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_longer</span>(<span class="sc">!</span><span class="fu">c</span>(t, epsilon))</span>
<span id="cb15-37"><a href="mod-bandit.html#cb15-37" aria-hidden="true" tabindex="-1"></a>   dat2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">t =</span> <span class="dv">1</span><span class="sc">:</span>steps) <span class="sc">%&gt;%</span></span>
<span id="cb15-38"><a href="mod-bandit.html#cb15-38" aria-hidden="true" tabindex="-1"></a>      <span class="fu">bind_cols</span>(best) <span class="sc">%&gt;%</span>   <span class="co"># bind data together</span></span>
<span id="cb15-39"><a href="mod-bandit.html#cb15-39" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_longer</span>(<span class="sc">!</span>t, <span class="at">values_to =</span> <span class="st">&quot;optimal&quot;</span>, <span class="at">names_to =</span> <span class="st">&quot;epsilon&quot;</span>) <span class="sc">%&gt;%</span>   </span>
<span id="cb15-40"><a href="mod-bandit.html#cb15-40" aria-hidden="true" tabindex="-1"></a>      <span class="fu">group_by</span>(epsilon) <span class="sc">%&gt;%</span> </span>
<span id="cb15-41"><a href="mod-bandit.html#cb15-41" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">All =</span> <span class="fu">cumsum</span>(optimal<span class="sc">/</span>runs)<span class="sc">/</span>t, <span class="st">`</span><span class="at">Moving avg (50)</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rollapply</span>(optimal<span class="sc">/</span>runs, <span class="dv">50</span>, mean, <span class="at">align =</span> <span class="st">&quot;right&quot;</span>, <span class="at">fill =</span> <span class="cn">NA</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb15-42"><a href="mod-bandit.html#cb15-42" aria-hidden="true" tabindex="-1"></a>      <span class="fu">select</span>(<span class="sc">-</span>optimal) <span class="sc">%&gt;%</span> </span>
<span id="cb15-43"><a href="mod-bandit.html#cb15-43" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_longer</span>(<span class="sc">!</span><span class="fu">c</span>(t, epsilon))</span>
<span id="cb15-44"><a href="mod-bandit.html#cb15-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># calc average</span></span>
<span id="cb15-45"><a href="mod-bandit.html#cb15-45" aria-hidden="true" tabindex="-1"></a>   pt1 <span class="ot">&lt;-</span> dat1 <span class="sc">%&gt;%</span> </span>
<span id="cb15-46"><a href="mod-bandit.html#cb15-46" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> t, <span class="at">y =</span> value, <span class="at">col =</span> epsilon, <span class="at">linetype =</span> name)) <span class="sc">+</span></span>
<span id="cb15-47"><a href="mod-bandit.html#cb15-47" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb15-48"><a href="mod-bandit.html#cb15-48" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Average reward per time unit&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Time&quot;</span>, <span class="at">title =</span> <span class="fu">str_c</span>(<span class="st">&quot;Average over &quot;</span>, runs, <span class="st">&quot; runs &quot;</span>), <span class="at">col =</span> <span class="st">&quot;Epsilon&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb15-49"><a href="mod-bandit.html#cb15-49" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span>
<span id="cb15-50"><a href="mod-bandit.html#cb15-50" aria-hidden="true" tabindex="-1"></a>   pt2 <span class="ot">&lt;-</span> dat2 <span class="sc">%&gt;%</span> </span>
<span id="cb15-51"><a href="mod-bandit.html#cb15-51" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> t, <span class="at">y =</span> value, <span class="at">col =</span> epsilon, <span class="at">linetype =</span> name)) <span class="sc">+</span></span>
<span id="cb15-52"><a href="mod-bandit.html#cb15-52" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb15-53"><a href="mod-bandit.html#cb15-53" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Average number of times optimal action chosen&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Time&quot;</span>, <span class="at">title =</span> <span class="fu">str_c</span>(<span class="st">&quot;Average over &quot;</span>, runs, <span class="st">&quot; runs&quot;</span>), <span class="at">col =</span> <span class="st">&quot;Epsilon&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb15-54"><a href="mod-bandit.html#cb15-54" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span>
<span id="cb15-55"><a href="mod-bandit.html#cb15-55" aria-hidden="true" tabindex="-1"></a>   <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">ptR =</span> pt1, <span class="at">ptO =</span> pt2))</span>
<span id="cb15-56"><a href="mod-bandit.html#cb15-56" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We test the performance using 2000 runs over 1000 time steps.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="mod-bandit.html#cb16-1" aria-hidden="true" tabindex="-1"></a>pts <span class="ot">&lt;-</span> <span class="fu">performance</span>(<span class="at">runs =</span> <span class="dv">2000</span>, <span class="at">steps =</span> <span class="dv">1000</span>)</span>
<span id="cb16-2"><a href="mod-bandit.html#cb16-2" aria-hidden="true" tabindex="-1"></a>pts<span class="sc">$</span>ptR</span>
<span id="cb16-3"><a href="mod-bandit.html#cb16-3" aria-hidden="true" tabindex="-1"></a>pts<span class="sc">$</span>ptO</span></code></pre></div>
<p><img src="02_bandit_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /><img src="02_bandit_files/figure-html/unnamed-chunk-8-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>The solid line shows averages over all the runs from <span class="math inline">\(t=1\)</span> to the considered time-step while the dotted line is a moving average over the last 50 time-steps. Since we are expected to learn over the time-steps the moving averages will in general be higher than the overall averages. Note that if we have 1000 time-steps a greedy approach in general is bad and an <span class="math inline">\(\epsilon\)</span>-greedy approach is better (<span class="math inline">\(\epsilon = 0.1\)</span> is best). That is, exploration is beneficial.</p>
</div>
<div id="sec-bandit-step-size" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> The role of the step-size<a href="mod-bandit.html#sec-bandit-step-size" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In general we update the reward estimate of an action using</p>
<p><span class="math display">\[\begin{equation}
    Q_{n+1} = Q_n +\alpha_n(a) \left[R_n - Q_n\right]
\end{equation}\]</span></p>
<p>Until now we have used the sample average <span class="math inline">\(\alpha_n(a)= 1/n\)</span>; however, other choices of <span class="math inline">\(\alpha_n(a)\)</span> is possible. In general we will converge to the true reward if</p>
<p><span class="math display">\[\begin{equation}
    \sum_n \alpha_n(a) = \infty \quad\quad \mathsf{and} \quad\quad  \sum_n \alpha_n(a)^2 &lt; \infty.
\end{equation}\]</span></p>
<p>Meaning that the coefficients must be large enough to recover from initial fluctuations, but not so large that they do not converge in the long run. However, if the process is non-stationary, i.e. the expected reward of an action change over time, then convergence is undesirable and we may want to use a constant <span class="math inline">\(\alpha_n(a)= \alpha \in (0, 1]\)</span> instead. This results in <span class="math inline">\(Q_{n+1}\)</span> being a weighted average of the past rewards and the initial estimate <span class="math inline">\(Q_1\)</span>:</p>
<p><span class="math display">\[\begin{align}
Q_{n+1} &amp;= Q_n +\alpha \left[R_n - Q_n\right] \nonumber \\
&amp;= \alpha R_n + (1 - \alpha)Q_n \nonumber \\
&amp;= \alpha R_n + (1 - \alpha)[\alpha R_{n-1} + (1 - \alpha)Q_{n-1}] \nonumber \\
&amp;= \alpha R_n + (1 - \alpha)\alpha R_{n-1} + (1 - \alpha)^2 Q_{n-1}  \nonumber \\
&amp;= \vdots \nonumber \\
&amp;= (1-\alpha)^n Q_1 + \sum_{i=1}^{n} \alpha (1 - \alpha)^{n-i} R_i \\
\end{align}\]</span></p>
<p>Because the weight given to each reward depends on how long ago it was observed, we can see that more recent rewards are given more weight. Note the weights <span class="math inline">\(\alpha\)</span> sum to 1 here, ensuring it is indeed a weighted average where more weight is allocated to recent rewards. Since the weight given to each reward decays exponentially into the past. This sometimes called an <em>exponential recency-weighted average</em>.</p>
</div>
<div id="optimistic-initial-values" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Optimistic initial values<a href="mod-bandit.html#optimistic-initial-values" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The methods discussed so far are dependent to some extent on the initial action-value estimate i.e. they are biased by their initial estimates. For methods with constant <span class="math inline">\(\alpha\)</span> this bias is permanent. We may set initial value estimates artificially high to encourage exploration in the short run. For instance, by setting initial values of <span class="math inline">\(Q\)</span> to 5 rather than 0 we encourage exploration, even in the greedy case. Here the agent will almost always be disappointed with it’s samples because they are less than the initial estimate and so will explore elsewhere until the values converge.</p>
</div>
<div id="upper-confidence-bound-action-selection" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Upper-Confidence Bound Action Selection<a href="mod-bandit.html#upper-confidence-bound-action-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An <span class="math inline">\(\epsilon\)</span>-greed algorithm choose the action to explore with equal probability in an exploration step. It would be better to select among non-greedy actions according to their potential for actually being optimal, taking into account both how close their estimates are to being maximal and the uncertainty in those estimates. One way to do this is to select actions using the <em>upper-confidence bound</em>:
<span class="math display">\[\begin{equation}
    A_t = \arg\max_a \left(Q_t(a) + c\sqrt{\frac{\ln t}{N_t(a)}}\right),
\end{equation}\]</span></p>
<p>Note the square root term is a measure of the uncertainty in our estimate (see Figure <a href="mod-bandit.html#fig:srt">2.3</a>).</p>
<ul>
<li>It is proportional to <span class="math inline">\(t\)</span> i.e. how many time-steps have passed and inversely proportional to <span class="math inline">\(N_t(a)\)</span> i.e. how many times that action has been visited.</li>
<li>The more time has passed, and the less we have sampled an action, the higher our upper-confidence-bound.</li>
<li>As the timesteps increases, the denominator dominates the numerator as the ln term flattens.</li>
<li>Each time we select an action our uncertainty decreases because <span class="math inline">\(N\)</span> is the denominator of this equation.</li>
<li>If <span class="math inline">\(N_t(a) = 0\)</span> then we consider <span class="math inline">\(a\)</span> as a maximal action, i.e. we select first among actions with <span class="math inline">\(N_t(a) = 0\)</span>.</li>
<li>The parameter <span class="math inline">\(c&gt;0\)</span> controls the degree of exploration. Higher <span class="math inline">\(c\)</span> results in more weight on the uncertainty.</li>
</ul>
<p>Since upper-confidence bound action selection select actions according to their potential, it is expected to perform better than <span class="math inline">\(\epsilon\)</span>-greedy methods.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:srt"></span>
<img src="02_bandit_files/figure-html/srt-1.png" alt="Square root term for an action using different $c$-values." width="672" />
<p class="caption">
Figure 2.3: Square root term for an action using different <span class="math inline">\(c\)</span>-values.
</p>
</div>
</div>
<div id="summary-1" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Summary<a href="mod-bandit.html#summary-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Read Chapter 2.10 in <span class="citation">Sutton and Barto (<a href="#ref-Sutton18" role="doc-biblioref">2018</a>)</span>.</p>
</div>
<div id="sec-bandit-ex" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Exercises<a href="mod-bandit.html#sec-bandit-ex" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Below you will find a set of exercises. Always have a look at the exercises before you meet in your study group and try to solve them yourself. Are you stuck, see the <a href="help.html#help">help page</a>. Sometimes solutions can be seen by pressing the button besides a question. Beware, you will not learn by giving up too early. Put some effort into finding a solution!</p>
<div id="ex-bandit-adv" class="section level3 hasAnchor" number="2.9.1">
<h3><span class="header-section-number">2.9.1</span> Exercise - Advertising<a href="mod-bandit.html#ex-bandit-adv" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose you are an advertiser seeking to optimize which ads to show visitors on a particular website. For each visitor, you can choose one out of a collection of ads, and your goal is to maximize the number of clicks over time. Assume that:</p>
<ul>
<li>You have <span class="math inline">\(k=5\)</span> adds to choose among.</li>
<li>If add <span class="math inline">\(A\)</span> is chosen then the user clicks the add with probability <span class="math inline">\(p_A\)</span> which can be seen as the unknown click trough rate CTR (or an average reward).</li>
<li>The CTRs are unknown and samples can be picked using the <code>RLAdEnv</code> class and the reward function which returns 1 if click on ad and 0 otherwise.</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="mod-bandit.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; R6 Class representing the RL advertising environment</span></span>
<span id="cb17-2"><a href="mod-bandit.html#cb17-2" aria-hidden="true" tabindex="-1"></a>RLAdEnv <span class="ot">&lt;-</span> <span class="fu">R6Class</span>(<span class="st">&quot;RLAdEnv&quot;</span>,</span>
<span id="cb17-3"><a href="mod-bandit.html#cb17-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">public =</span> <span class="fu">list</span>(</span>
<span id="cb17-4"><a href="mod-bandit.html#cb17-4" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field mV Click trough rates</span></span>
<span id="cb17-5"><a href="mod-bandit.html#cb17-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">mV =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.83</span>, <span class="fl">0.85</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>),  </span>
<span id="cb17-6"><a href="mod-bandit.html#cb17-6" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb17-7"><a href="mod-bandit.html#cb17-7" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field k Number of ads.</span></span>
<span id="cb17-8"><a href="mod-bandit.html#cb17-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">k =</span> <span class="dv">5</span>,   </span>
<span id="cb17-9"><a href="mod-bandit.html#cb17-9" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb17-10"><a href="mod-bandit.html#cb17-10" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Sample reward of a bandit.</span></span>
<span id="cb17-11"><a href="mod-bandit.html#cb17-11" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param a Bandit/ad (index).</span></span>
<span id="cb17-12"><a href="mod-bandit.html#cb17-12" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return One if click on ad and zero otherwise.</span></span>
<span id="cb17-13"><a href="mod-bandit.html#cb17-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">reward =</span> <span class="cf">function</span>(a) {</span>
<span id="cb17-14"><a href="mod-bandit.html#cb17-14" aria-hidden="true" tabindex="-1"></a>         <span class="fu">return</span>(<span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">1</span>, self<span class="sc">$</span>mV[a]))</span>
<span id="cb17-15"><a href="mod-bandit.html#cb17-15" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb17-16"><a href="mod-bandit.html#cb17-16" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb17-17"><a href="mod-bandit.html#cb17-17" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Returns action with best mean.</span></span>
<span id="cb17-18"><a href="mod-bandit.html#cb17-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">optimalAction =</span> <span class="cf">function</span>() <span class="fu">return</span>(<span class="fu">which.max</span>(self<span class="sc">$</span>mV))</span>
<span id="cb17-19"><a href="mod-bandit.html#cb17-19" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb17-20"><a href="mod-bandit.html#cb17-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-21"><a href="mod-bandit.html#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="mod-bandit.html#cb17-22" aria-hidden="true" tabindex="-1"></a>env <span class="ot">&lt;-</span> RLAdEnv<span class="sc">$</span><span class="fu">new</span>()</span>
<span id="cb17-23"><a href="mod-bandit.html#cb17-23" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span><span class="fu">reward</span>(<span class="dv">2</span>)  <span class="co"># click on ad number two (return 0 or 1)?</span></span>
<span id="cb17-24"><a href="mod-bandit.html#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb17-25"><a href="mod-bandit.html#cb17-25" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span><span class="fu">optimalAction</span>()  <span class="co"># the best ad</span></span>
<span id="cb17-26"><a href="mod-bandit.html#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 3</span></span>
<span id="cb17-27"><a href="mod-bandit.html#cb17-27" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span>mV  <span class="co"># true CTRs</span></span>
<span id="cb17-28"><a href="mod-bandit.html#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.10 0.83 0.85 0.50 0.70</span></span></code></pre></div>
<p>In the class the true CTRs can be observed but in practice this is hidden from the agent (you).</p>
<p>Consider an <span class="math inline">\(\epsilon\)</span>-greedy algorithm to find the best ad. Assume the webpage is visited by 10000 users per day.</p>
<!-- Q1 -->
<div id="bBIs4ifgbS5F91wS3KgW" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="bBIs4ifgbS5F91wS3KgW-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="bBIs4ifgbS5F91wS3KgW-title">
Solution
</h4>
</div>
<div class="modal-body">
<div class="sourceCode" id="cb18"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb18-1"><a href="mod-bandit.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">327</span>)  <span class="co"># to get same results </span></span>
<span id="cb18-2"><a href="mod-bandit.html#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="mod-bandit.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; Performance of the bandit algorithm.</span></span>
<span id="cb18-4"><a href="mod-bandit.html#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @param steps Steps (users).</span></span>
<span id="cb18-5"><a href="mod-bandit.html#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @param epsilon Epsilon to be tested.</span></span>
<span id="cb18-6"><a href="mod-bandit.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; @return A list with statistics.</span></span>
<span id="cb18-7"><a href="mod-bandit.html#cb18-7" aria-hidden="true" tabindex="-1"></a>testEG <span class="ot">&lt;-</span> <span class="cf">function</span>(epsilon, <span class="at">steps =</span> <span class="dv">10000</span>) {</span>
<span id="cb18-8"><a href="mod-bandit.html#cb18-8" aria-hidden="true" tabindex="-1"></a>   agent <span class="ot">&lt;-</span> RLAgent<span class="sc">$</span><span class="fu">new</span>(<span class="at">k =</span> <span class="dv">5</span>, <span class="at">epsilon =</span> epsilon)</span>
<span id="cb18-9"><a href="mod-bandit.html#cb18-9" aria-hidden="true" tabindex="-1"></a>   rew <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb18-10"><a href="mod-bandit.html#cb18-10" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps) {</span>
<span id="cb18-11"><a href="mod-bandit.html#cb18-11" aria-hidden="true" tabindex="-1"></a>      a <span class="ot">&lt;-</span> agent<span class="sc">$</span><span class="fu">selectActionEG</span>()</span>
<span id="cb18-12"><a href="mod-bandit.html#cb18-12" aria-hidden="true" tabindex="-1"></a>      r <span class="ot">&lt;-</span> env<span class="sc">$</span><span class="fu">reward</span>(a)</span>
<span id="cb18-13"><a href="mod-bandit.html#cb18-13" aria-hidden="true" tabindex="-1"></a>      rew <span class="ot">&lt;-</span> rew <span class="sc">+</span> r</span>
<span id="cb18-14"><a href="mod-bandit.html#cb18-14" aria-hidden="true" tabindex="-1"></a>      agent<span class="sc">$</span><span class="fu">updateQ</span>(a, r)</span>
<span id="cb18-15"><a href="mod-bandit.html#cb18-15" aria-hidden="true" tabindex="-1"></a>   }</span>
<span id="cb18-16"><a href="mod-bandit.html#cb18-16" aria-hidden="true" tabindex="-1"></a>   <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">qV =</span> agent<span class="sc">$</span>qV, <span class="at">avgReward =</span> rew<span class="sc">/</span>steps))</span>
<span id="cb18-17"><a href="mod-bandit.html#cb18-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-18"><a href="mod-bandit.html#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="fu">testEG</span>(<span class="fl">0.01</span>)</span>
<span id="cb18-19"><a href="mod-bandit.html#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb18-20"><a href="mod-bandit.html#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.000 0.800 0.852 0.409 0.654</span></span>
<span id="cb18-21"><a href="mod-bandit.html#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-22"><a href="mod-bandit.html#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb18-23"><a href="mod-bandit.html#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.849</span></span>
<span id="cb18-24"><a href="mod-bandit.html#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="fu">testEG</span>(<span class="fl">0.1</span>)</span>
<span id="cb18-25"><a href="mod-bandit.html#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb18-26"><a href="mod-bandit.html#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.119 0.843 0.849 0.516 0.685</span></span>
<span id="cb18-27"><a href="mod-bandit.html#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-28"><a href="mod-bandit.html#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb18-29"><a href="mod-bandit.html#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.824</span></span>
<span id="cb18-30"><a href="mod-bandit.html#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="fu">testEG</span>(<span class="fl">0.5</span>)</span>
<span id="cb18-31"><a href="mod-bandit.html#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb18-32"><a href="mod-bandit.html#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.110 0.844 0.851 0.484 0.703</span></span>
<span id="cb18-33"><a href="mod-bandit.html#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-34"><a href="mod-bandit.html#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb18-35"><a href="mod-bandit.html#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.725</span></span>
<span id="cb18-36"><a href="mod-bandit.html#cb18-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-37"><a href="mod-bandit.html#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="co"># True values</span></span>
<span id="cb18-38"><a href="mod-bandit.html#cb18-38" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span><span class="fu">optimalAction</span>()</span>
<span id="cb18-39"><a href="mod-bandit.html#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 3</span></span>
<span id="cb18-40"><a href="mod-bandit.html#cb18-40" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span>mV</span>
<span id="cb18-41"><a href="mod-bandit.html#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.10 0.83 0.85 0.50 0.70</span></span></code></pre></div>
<p>
Epsilon = 0.01 seems to give the best average number of clicks.
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#bBIs4ifgbS5F91wS3KgW">
Solution
</button>
<ol style="list-style-type: decimal">
<li>Run the <span class="math inline">\(\epsilon\)</span>-greedy algorithm with <span class="math inline">\(\epsilon = 0.01, 0.1, 0.5\)</span> over the 10000 steps. What are the estimated CTRs for each action (<span class="math inline">\(Q_t(a)\)</span>)? What is the average number of clicks per user?</li>
</ol>
<!-- Q2 -->
<div id="9UNSaGJghbZYV0FR4kTI" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="9UNSaGJghbZYV0FR4kTI-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="9UNSaGJghbZYV0FR4kTI-title">
Solution
</h4>
</div>
<div class="modal-body">
<div class="sourceCode" id="cb19"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb19-1"><a href="mod-bandit.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Test function modified with plot feature</span></span>
<span id="cb19-2"><a href="mod-bandit.html#cb19-2" aria-hidden="true" tabindex="-1"></a>testEG <span class="ot">&lt;-</span> <span class="cf">function</span>(epsilon, <span class="at">steps =</span> <span class="dv">10000</span>) {</span>
<span id="cb19-3"><a href="mod-bandit.html#cb19-3" aria-hidden="true" tabindex="-1"></a>   agent <span class="ot">&lt;-</span> RLAgent<span class="sc">$</span><span class="fu">new</span>(<span class="at">k =</span> <span class="dv">5</span>, <span class="at">epsilon =</span> epsilon)</span>
<span id="cb19-4"><a href="mod-bandit.html#cb19-4" aria-hidden="true" tabindex="-1"></a>   rew <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb19-5"><a href="mod-bandit.html#cb19-5" aria-hidden="true" tabindex="-1"></a>   qVal <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> steps, <span class="at">ncol =</span> <span class="dv">5</span>)</span>
<span id="cb19-6"><a href="mod-bandit.html#cb19-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">colnames</span>(qVal) <span class="ot">=</span> <span class="fu">str_c</span>(<span class="st">&quot;A&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span>
<span id="cb19-7"><a href="mod-bandit.html#cb19-7" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps) {</span>
<span id="cb19-8"><a href="mod-bandit.html#cb19-8" aria-hidden="true" tabindex="-1"></a>      a <span class="ot">&lt;-</span> agent<span class="sc">$</span><span class="fu">selectActionEG</span>()</span>
<span id="cb19-9"><a href="mod-bandit.html#cb19-9" aria-hidden="true" tabindex="-1"></a>      r <span class="ot">&lt;-</span> env<span class="sc">$</span><span class="fu">reward</span>(a)</span>
<span id="cb19-10"><a href="mod-bandit.html#cb19-10" aria-hidden="true" tabindex="-1"></a>      rew <span class="ot">&lt;-</span> rew <span class="sc">+</span> r</span>
<span id="cb19-11"><a href="mod-bandit.html#cb19-11" aria-hidden="true" tabindex="-1"></a>      agent<span class="sc">$</span><span class="fu">updateQ</span>(a, r)</span>
<span id="cb19-12"><a href="mod-bandit.html#cb19-12" aria-hidden="true" tabindex="-1"></a>      qVal[t,] <span class="ot">&lt;-</span> agent<span class="sc">$</span>qV</span>
<span id="cb19-13"><a href="mod-bandit.html#cb19-13" aria-hidden="true" tabindex="-1"></a>   }</span>
<span id="cb19-14"><a href="mod-bandit.html#cb19-14" aria-hidden="true" tabindex="-1"></a>   <span class="co"># make plot</span></span>
<span id="cb19-15"><a href="mod-bandit.html#cb19-15" aria-hidden="true" tabindex="-1"></a>   dat <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">t =</span> <span class="dv">1</span><span class="sc">:</span>steps) <span class="sc">%&gt;%</span></span>
<span id="cb19-16"><a href="mod-bandit.html#cb19-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">bind_cols</span>(qVal) <span class="sc">%&gt;%</span>   <span class="co"># bind data together</span></span>
<span id="cb19-17"><a href="mod-bandit.html#cb19-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pivot_longer</span>(<span class="sc">!</span>t, <span class="at">values_to =</span> <span class="st">&quot;ctr&quot;</span>, <span class="at">names_to =</span> <span class="st">&quot;action&quot;</span>) </span>
<span id="cb19-18"><a href="mod-bandit.html#cb19-18" aria-hidden="true" tabindex="-1"></a>   pt <span class="ot">&lt;-</span> dat <span class="sc">%&gt;%</span> </span>
<span id="cb19-19"><a href="mod-bandit.html#cb19-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> t, <span class="at">y =</span> ctr, <span class="at">col =</span> action)) <span class="sc">+</span></span>
<span id="cb19-20"><a href="mod-bandit.html#cb19-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb19-21"><a href="mod-bandit.html#cb19-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Empirical CTRs&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Time&quot;</span>, <span class="at">title =</span> <span class="fu">str_c</span>(<span class="st">&quot;CTRs eps = &quot;</span>, epsilon), <span class="at">col =</span> <span class="st">&quot;Action&quot;</span>) <span class="sc">+</span></span>
<span id="cb19-22"><a href="mod-bandit.html#cb19-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span>
<span id="cb19-23"><a href="mod-bandit.html#cb19-23" aria-hidden="true" tabindex="-1"></a>   <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">qV =</span> agent<span class="sc">$</span>qV, <span class="at">avgReward =</span> rew<span class="sc">/</span>steps, <span class="at">plt =</span> pt))</span>
<span id="cb19-24"><a href="mod-bandit.html#cb19-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-25"><a href="mod-bandit.html#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="fu">testEG</span>(<span class="fl">0.01</span>)<span class="sc">$</span>plt</span>
<span id="cb19-26"><a href="mod-bandit.html#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="fu">testEG</span>(<span class="fl">0.5</span>)<span class="sc">$</span>plt</span></code></pre></div>
<img src="02_bandit_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /><img src="02_bandit_files/figure-html/unnamed-chunk-11-2.png" width="672" style="display: block; margin: auto;" />
<p>
As epsilon grows we estimate the true values better for all actions.
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#9UNSaGJghbZYV0FR4kTI">
Solution
</button>
<ol start="2" style="list-style-type: decimal">
<li>Make a plot of the empirical CTRs for <span class="math inline">\(\epsilon = 0.01, 0.5\)</span> over 10000 time-steps, i.e. plot <span class="math inline">\(Q_t(a)\)</span>.</li>
</ol>
<!-- Q3 -->
<div id="cJNysHsWq0UWK5lQcvNQ" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="cJNysHsWq0UWK5lQcvNQ-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="cJNysHsWq0UWK5lQcvNQ-title">
Solution
</h4>
</div>
<div class="modal-body">
<div class="sourceCode" id="cb20"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb20-1"><a href="mod-bandit.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Test function modified with rewards</span></span>
<span id="cb20-2"><a href="mod-bandit.html#cb20-2" aria-hidden="true" tabindex="-1"></a>testEG <span class="ot">&lt;-</span> <span class="cf">function</span>(epsilon, <span class="at">steps =</span> <span class="dv">10000</span>) {</span>
<span id="cb20-3"><a href="mod-bandit.html#cb20-3" aria-hidden="true" tabindex="-1"></a>   agent <span class="ot">&lt;-</span> RLAgent<span class="sc">$</span><span class="fu">new</span>(<span class="at">k =</span> <span class="dv">5</span>, <span class="at">epsilon =</span> epsilon)</span>
<span id="cb20-4"><a href="mod-bandit.html#cb20-4" aria-hidden="true" tabindex="-1"></a>   rewards <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">8</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">2</span>)</span>
<span id="cb20-5"><a href="mod-bandit.html#cb20-5" aria-hidden="true" tabindex="-1"></a>   rew <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb20-6"><a href="mod-bandit.html#cb20-6" aria-hidden="true" tabindex="-1"></a>   qVal <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> <span class="dv">10000</span>, <span class="at">ncol =</span> <span class="dv">5</span>)</span>
<span id="cb20-7"><a href="mod-bandit.html#cb20-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">colnames</span>(qVal) <span class="ot">=</span> <span class="fu">str_c</span>(<span class="st">&quot;A&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span>
<span id="cb20-8"><a href="mod-bandit.html#cb20-8" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps) {</span>
<span id="cb20-9"><a href="mod-bandit.html#cb20-9" aria-hidden="true" tabindex="-1"></a>      a <span class="ot">&lt;-</span> agent<span class="sc">$</span><span class="fu">selectActionEG</span>()</span>
<span id="cb20-10"><a href="mod-bandit.html#cb20-10" aria-hidden="true" tabindex="-1"></a>      r <span class="ot">&lt;-</span> env<span class="sc">$</span><span class="fu">reward</span>(a) <span class="sc">*</span> rewards[a]</span>
<span id="cb20-11"><a href="mod-bandit.html#cb20-11" aria-hidden="true" tabindex="-1"></a>      rew <span class="ot">&lt;-</span> rew <span class="sc">+</span> r</span>
<span id="cb20-12"><a href="mod-bandit.html#cb20-12" aria-hidden="true" tabindex="-1"></a>      agent<span class="sc">$</span><span class="fu">updateQ</span>(a, r)</span>
<span id="cb20-13"><a href="mod-bandit.html#cb20-13" aria-hidden="true" tabindex="-1"></a>      qVal[t,] <span class="ot">&lt;-</span> agent<span class="sc">$</span>qV</span>
<span id="cb20-14"><a href="mod-bandit.html#cb20-14" aria-hidden="true" tabindex="-1"></a>   }</span>
<span id="cb20-15"><a href="mod-bandit.html#cb20-15" aria-hidden="true" tabindex="-1"></a>   <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">qV =</span> agent<span class="sc">$</span>qV, <span class="at">avgReward =</span> rew<span class="sc">/</span>steps))</span>
<span id="cb20-16"><a href="mod-bandit.html#cb20-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-17"><a href="mod-bandit.html#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="fu">testEG</span>(<span class="fl">0.01</span>)</span>
<span id="cb20-18"><a href="mod-bandit.html#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb20-19"><a href="mod-bandit.html#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.909 6.565 4.583 7.607 1.378</span></span>
<span id="cb20-20"><a href="mod-bandit.html#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-21"><a href="mod-bandit.html#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb20-22"><a href="mod-bandit.html#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 6.83</span></span>
<span id="cb20-23"><a href="mod-bandit.html#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="fu">testEG</span>(<span class="fl">0.5</span>)</span>
<span id="cb20-24"><a href="mod-bandit.html#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb20-25"><a href="mod-bandit.html#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.952 6.640 4.290 7.459 1.355</span></span>
<span id="cb20-26"><a href="mod-bandit.html#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-27"><a href="mod-bandit.html#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb20-28"><a href="mod-bandit.html#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 5.74</span></span>
<span id="cb20-29"><a href="mod-bandit.html#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="mod-bandit.html#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="co"># True average reward values</span></span>
<span id="cb20-31"><a href="mod-bandit.html#cb20-31" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span>mV <span class="sc">*</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">8</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">2</span>)</span>
<span id="cb20-32"><a href="mod-bandit.html#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.00 6.64 4.25 7.50 1.40</span></span></code></pre></div>
<p>
The best action is now 4 and eps = 0.01 seems to give the best overall average reward.
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#cJNysHsWq0UWK5lQcvNQ">
Solution
</button>
<ol start="3" style="list-style-type: decimal">
<li>Assume that the rewards of ad clicks is equal to (10, 8, 5, 15, 2). Modify the algorithm so you look at rewards instead of CTRs. What is the best action to choose?</li>
</ol>
<!-- Q4 -->
<p>We now modify the RLAgent and add an upper-confidence bound function <code>selectActionUCB</code>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="mod-bandit.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39; R6 Class representing the RL agent</span></span>
<span id="cb21-2"><a href="mod-bandit.html#cb21-2" aria-hidden="true" tabindex="-1"></a>RLAgent <span class="ot">&lt;-</span> <span class="fu">R6Class</span>(<span class="st">&quot;RLAgent&quot;</span>,</span>
<span id="cb21-3"><a href="mod-bandit.html#cb21-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">public =</span> <span class="fu">list</span>(</span>
<span id="cb21-4"><a href="mod-bandit.html#cb21-4" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field qV Q estimates.</span></span>
<span id="cb21-5"><a href="mod-bandit.html#cb21-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">qV =</span> <span class="cn">NULL</span>,  </span>
<span id="cb21-6"><a href="mod-bandit.html#cb21-6" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-7"><a href="mod-bandit.html#cb21-7" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field nV Action counter.</span></span>
<span id="cb21-8"><a href="mod-bandit.html#cb21-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">nV =</span> <span class="cn">NULL</span>,  </span>
<span id="cb21-9"><a href="mod-bandit.html#cb21-9" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-10"><a href="mod-bandit.html#cb21-10" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field k Number of bandits.</span></span>
<span id="cb21-11"><a href="mod-bandit.html#cb21-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">k =</span> <span class="cn">NULL</span>,   </span>
<span id="cb21-12"><a href="mod-bandit.html#cb21-12" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-13"><a href="mod-bandit.html#cb21-13" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @field epsilon Epsilon used in epsilon greed action selection.</span></span>
<span id="cb21-14"><a href="mod-bandit.html#cb21-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">epsilon =</span> <span class="cn">NULL</span>, </span>
<span id="cb21-15"><a href="mod-bandit.html#cb21-15" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-16"><a href="mod-bandit.html#cb21-16" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Create an object (when call new).</span></span>
<span id="cb21-17"><a href="mod-bandit.html#cb21-17" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param k Number of bandits.</span></span>
<span id="cb21-18"><a href="mod-bandit.html#cb21-18" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param epsilon Epsilon used in epsilon greed action selection.</span></span>
<span id="cb21-19"><a href="mod-bandit.html#cb21-19" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return The new object.</span></span>
<span id="cb21-20"><a href="mod-bandit.html#cb21-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">initialize =</span> <span class="cf">function</span>(<span class="at">k =</span> <span class="dv">10</span>, <span class="at">epsilon =</span> <span class="fl">0.01</span>, <span class="at">ini =</span>  <span class="dv">0</span>) {</span>
<span id="cb21-21"><a href="mod-bandit.html#cb21-21" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>epsilon <span class="ot">&lt;-</span> epsilon</span>
<span id="cb21-22"><a href="mod-bandit.html#cb21-22" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>qV <span class="ot">&lt;-</span> <span class="fu">rep</span>(ini, k)</span>
<span id="cb21-23"><a href="mod-bandit.html#cb21-23" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>nV <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k)</span>
<span id="cb21-24"><a href="mod-bandit.html#cb21-24" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>k <span class="ot">&lt;-</span> k</span>
<span id="cb21-25"><a href="mod-bandit.html#cb21-25" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb21-26"><a href="mod-bandit.html#cb21-26" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-27"><a href="mod-bandit.html#cb21-27" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Clear learning.</span></span>
<span id="cb21-28"><a href="mod-bandit.html#cb21-28" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param eps Epsilon.</span></span>
<span id="cb21-29"><a href="mod-bandit.html#cb21-29" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return Action (index).</span></span>
<span id="cb21-30"><a href="mod-bandit.html#cb21-30" aria-hidden="true" tabindex="-1"></a>      <span class="at">clearLearning =</span> <span class="cf">function</span>() {</span>
<span id="cb21-31"><a href="mod-bandit.html#cb21-31" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>qV <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb21-32"><a href="mod-bandit.html#cb21-32" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>nV <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb21-33"><a href="mod-bandit.html#cb21-33" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb21-34"><a href="mod-bandit.html#cb21-34" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-35"><a href="mod-bandit.html#cb21-35" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Select next action using an epsilon greedy strategy.</span></span>
<span id="cb21-36"><a href="mod-bandit.html#cb21-36" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return Action (index).</span></span>
<span id="cb21-37"><a href="mod-bandit.html#cb21-37" aria-hidden="true" tabindex="-1"></a>      <span class="at">selectActionEG =</span> <span class="cf">function</span>() {   </span>
<span id="cb21-38"><a href="mod-bandit.html#cb21-38" aria-hidden="true" tabindex="-1"></a>         <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;=</span> self<span class="sc">$</span>epsilon) { <span class="co"># explore</span></span>
<span id="cb21-39"><a href="mod-bandit.html#cb21-39" aria-hidden="true" tabindex="-1"></a>            a <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>self<span class="sc">$</span>k, <span class="dv">1</span>)</span>
<span id="cb21-40"><a href="mod-bandit.html#cb21-40" aria-hidden="true" tabindex="-1"></a>         } <span class="cf">else</span> { <span class="co"># exploit</span></span>
<span id="cb21-41"><a href="mod-bandit.html#cb21-41" aria-hidden="true" tabindex="-1"></a>            a <span class="ot">&lt;-</span> <span class="fu">which</span>(self<span class="sc">$</span>qV <span class="sc">==</span> <span class="fu">max</span>(self<span class="sc">$</span>qV))</span>
<span id="cb21-42"><a href="mod-bandit.html#cb21-42" aria-hidden="true" tabindex="-1"></a>            a <span class="ot">&lt;-</span> a[<span class="fu">sample</span>(<span class="fu">length</span>(a), <span class="dv">1</span>)]</span>
<span id="cb21-43"><a href="mod-bandit.html#cb21-43" aria-hidden="true" tabindex="-1"></a>         }</span>
<span id="cb21-44"><a href="mod-bandit.html#cb21-44" aria-hidden="true" tabindex="-1"></a>         <span class="fu">return</span>(a)</span>
<span id="cb21-45"><a href="mod-bandit.html#cb21-45" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb21-46"><a href="mod-bandit.html#cb21-46" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-47"><a href="mod-bandit.html#cb21-47" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Select next action using UCB </span></span>
<span id="cb21-48"><a href="mod-bandit.html#cb21-48" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return Action (index).</span></span>
<span id="cb21-49"><a href="mod-bandit.html#cb21-49" aria-hidden="true" tabindex="-1"></a>      <span class="at">selectActionUCB =</span> <span class="cf">function</span>(c, t) {   </span>
<span id="cb21-50"><a href="mod-bandit.html#cb21-50" aria-hidden="true" tabindex="-1"></a>         val <span class="ot">&lt;-</span> self<span class="sc">$</span>qV <span class="sc">+</span> c <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">log</span>(t <span class="sc">+</span> <span class="fl">0.01</span>)<span class="sc">/</span>self<span class="sc">$</span>nV)</span>
<span id="cb21-51"><a href="mod-bandit.html#cb21-51" aria-hidden="true" tabindex="-1"></a>         a <span class="ot">&lt;-</span> <span class="fu">which.max</span>(val)</span>
<span id="cb21-52"><a href="mod-bandit.html#cb21-52" aria-hidden="true" tabindex="-1"></a>         <span class="fu">return</span>(a)</span>
<span id="cb21-53"><a href="mod-bandit.html#cb21-53" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb21-54"><a href="mod-bandit.html#cb21-54" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb21-55"><a href="mod-bandit.html#cb21-55" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @description Update learning values (including action counter).</span></span>
<span id="cb21-56"><a href="mod-bandit.html#cb21-56" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param a Action.</span></span>
<span id="cb21-57"><a href="mod-bandit.html#cb21-57" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @param r Reward.</span></span>
<span id="cb21-58"><a href="mod-bandit.html#cb21-58" aria-hidden="true" tabindex="-1"></a>      <span class="co">#&#39; @return NULL (invisible)</span></span>
<span id="cb21-59"><a href="mod-bandit.html#cb21-59" aria-hidden="true" tabindex="-1"></a>      <span class="at">updateQ =</span> <span class="cf">function</span>(a, r) {</span>
<span id="cb21-60"><a href="mod-bandit.html#cb21-60" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>nV[a] <span class="ot">&lt;-</span> self<span class="sc">$</span>nV[a] <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb21-61"><a href="mod-bandit.html#cb21-61" aria-hidden="true" tabindex="-1"></a>         self<span class="sc">$</span>qV[a] <span class="ot">&lt;-</span> self<span class="sc">$</span>qV[a] <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>self<span class="sc">$</span>nV[a] <span class="sc">*</span> (r <span class="sc">-</span> self<span class="sc">$</span>qV[a])</span>
<span id="cb21-62"><a href="mod-bandit.html#cb21-62" aria-hidden="true" tabindex="-1"></a>         <span class="fu">return</span>(<span class="fu">invisible</span>(<span class="cn">NULL</span>))</span>
<span id="cb21-63"><a href="mod-bandit.html#cb21-63" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb21-64"><a href="mod-bandit.html#cb21-64" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb21-65"><a href="mod-bandit.html#cb21-65" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div id="mhFyML8wY85v311DV6ie" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="mhFyML8wY85v311DV6ie-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="mhFyML8wY85v311DV6ie-title">
Solution
</h4>
</div>
<div class="modal-body">
<div class="sourceCode" id="cb22"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb22-1"><a href="mod-bandit.html#cb22-1" aria-hidden="true" tabindex="-1"></a>testUCB <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">c =</span> <span class="dv">2</span>, <span class="at">steps =</span> <span class="dv">10000</span>) {</span>
<span id="cb22-2"><a href="mod-bandit.html#cb22-2" aria-hidden="true" tabindex="-1"></a>   agent <span class="ot">&lt;-</span> RLAgent<span class="sc">$</span><span class="fu">new</span>(<span class="at">k =</span> <span class="dv">5</span>)</span>
<span id="cb22-3"><a href="mod-bandit.html#cb22-3" aria-hidden="true" tabindex="-1"></a>   rewards <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">8</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">2</span>)</span>
<span id="cb22-4"><a href="mod-bandit.html#cb22-4" aria-hidden="true" tabindex="-1"></a>   rew <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb22-5"><a href="mod-bandit.html#cb22-5" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps) {</span>
<span id="cb22-6"><a href="mod-bandit.html#cb22-6" aria-hidden="true" tabindex="-1"></a>      a <span class="ot">&lt;-</span> agent<span class="sc">$</span><span class="fu">selectActionUCB</span>(c, t)</span>
<span id="cb22-7"><a href="mod-bandit.html#cb22-7" aria-hidden="true" tabindex="-1"></a>      r <span class="ot">&lt;-</span> env<span class="sc">$</span><span class="fu">reward</span>(a) <span class="sc">*</span> rewards[a]</span>
<span id="cb22-8"><a href="mod-bandit.html#cb22-8" aria-hidden="true" tabindex="-1"></a>      rew <span class="ot">&lt;-</span> rew <span class="sc">+</span> r</span>
<span id="cb22-9"><a href="mod-bandit.html#cb22-9" aria-hidden="true" tabindex="-1"></a>      agent<span class="sc">$</span><span class="fu">updateQ</span>(a, r)</span>
<span id="cb22-10"><a href="mod-bandit.html#cb22-10" aria-hidden="true" tabindex="-1"></a>   }</span>
<span id="cb22-11"><a href="mod-bandit.html#cb22-11" aria-hidden="true" tabindex="-1"></a>   <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">qV =</span> agent<span class="sc">$</span>qV, <span class="at">avgReward =</span> rew<span class="sc">/</span>steps))</span>
<span id="cb22-12"><a href="mod-bandit.html#cb22-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-13"><a href="mod-bandit.html#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="fu">testUCB</span>(<span class="fl">0.1</span>)</span>
<span id="cb22-14"><a href="mod-bandit.html#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb22-15"><a href="mod-bandit.html#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.00 6.63 3.75 0.00 0.00</span></span>
<span id="cb22-16"><a href="mod-bandit.html#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb22-17"><a href="mod-bandit.html#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb22-18"><a href="mod-bandit.html#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 6.63</span></span>
<span id="cb22-19"><a href="mod-bandit.html#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="fu">testUCB</span>(<span class="dv">5</span>)</span>
<span id="cb22-20"><a href="mod-bandit.html#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb22-21"><a href="mod-bandit.html#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 2.22 6.48 3.68 7.46 1.43</span></span>
<span id="cb22-22"><a href="mod-bandit.html#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb22-23"><a href="mod-bandit.html#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb22-24"><a href="mod-bandit.html#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 7.28</span></span>
<span id="cb22-25"><a href="mod-bandit.html#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="fu">testUCB</span>(<span class="dv">10</span>)</span>
<span id="cb22-26"><a href="mod-bandit.html#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb22-27"><a href="mod-bandit.html#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.556 6.586 3.952 7.502 1.680</span></span>
<span id="cb22-28"><a href="mod-bandit.html#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb22-29"><a href="mod-bandit.html#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb22-30"><a href="mod-bandit.html#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 7.4</span></span>
<span id="cb22-31"><a href="mod-bandit.html#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="fu">testUCB</span>(<span class="dv">20</span>)</span>
<span id="cb22-32"><a href="mod-bandit.html#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $qV</span></span>
<span id="cb22-33"><a href="mod-bandit.html#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.48 6.62 4.25 7.56 1.42</span></span>
<span id="cb22-34"><a href="mod-bandit.html#cb22-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb22-35"><a href="mod-bandit.html#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $avgReward</span></span>
<span id="cb22-36"><a href="mod-bandit.html#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 7.25</span></span></code></pre></div>
<p>
A value <span class="math inline">\(c = 10\)</span> seems to be a good choice.
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#mhFyML8wY85v311DV6ie">
Solution
</button>
<ol start="4" style="list-style-type: decimal">
<li>Test the UCB algorithm for <span class="math inline">\(c\)</span> values <span class="math inline">\((0.1, 5, 10, 20)\)</span>. Which algorithm seems to find the best average reward?</li>
</ol>
</div>
<div id="ex-bandit-coin" class="section level3 hasAnchor" number="2.9.2">
<h3><span class="header-section-number">2.9.2</span> Exercise - A coin game<a href="mod-bandit.html#ex-bandit-coin" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a game where you choose to flip one of two (possibly unfair) coins. You win 1 if your chosen coin shows heads and lose 1 if it shows tails.</p>
<!-- Q1 -->
<div id="UogJuRebD8e68uuMCu63" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="UogJuRebD8e68uuMCu63-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="UogJuRebD8e68uuMCu63-title">
Solution
</h4>
</div>
<div class="modal-body">
<p>
This is a 2-bandit problem with actions of choosing coin 1 or 2.
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#UogJuRebD8e68uuMCu63">
Solution
</button>
<ol style="list-style-type: decimal">
<li>Model this as a K-armed bandit problem: define the action set.</li>
</ol>
<!-- Q2 -->
<div id="j7xBii6afnYS2GOohDOT" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="j7xBii6afnYS2GOohDOT-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="j7xBii6afnYS2GOohDOT-title">
Solution
</h4>
</div>
<div class="modal-body">
<p>
The reward is stochastic. If consider coin <span class="math inline">\(i\)</span> then <span class="math inline">\(\mathbb{E}[R_t | a_i] = \Pr(H)\cdot 1.\)</span>
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#j7xBii6afnYS2GOohDOT">
Solution
</button>
<ol start="2" style="list-style-type: decimal">
<li>Is the reward a deterministic or stochastic function of your action?</li>
</ol>
<!-- Q3 -->
<div id="taUUQrBS46oTgD01U7Dm" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="taUUQrBS46oTgD01U7Dm-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="taUUQrBS46oTgD01U7Dm-title">
Solution
</h4>
</div>
<div class="modal-body">
<p>
The estimates are <span class="math display">\[Q_t(a_1) = (0+1+1+0+0+0)/6 = 1/3\]</span> and <span class="math display">\[Q_t(a_2) = (1+0+1+1+1+0)/6 = 2/3\]</span>.
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#taUUQrBS46oTgD01U7Dm">
Solution
</button>
<ol start="3" style="list-style-type: decimal">
<li>You do not know the coin flip probabilities. Instead, you are able to view 6 sample flips for each coin respectively: (T,H,H,T,T,T) and (H,T,H,H,H,T). Use the sample average formula <a href="mod-bandit.html#eq:avg">(2.1)</a> to compute the estimates of the value of each action.</li>
</ol>
<!-- Q4 -->
<div id="nLBA4bBzteJ1obnKYNQ5" class="modal fade bs-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="nLBA4bBzteJ1obnKYNQ5-title">
<div class="modal-dialog modal-lg" role="document">
<div class="modal-content">
<div class="modal-header">
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">×</span>
</button>
<h4 class="modal-title" id="nLBA4bBzteJ1obnKYNQ5-title">
Solution
</h4>
</div>
<div class="modal-body">
<p>
Coin 2 is chosen since the best action-value.
</p>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal">
Close
</button>
</div>
</div>
</div>
</div>
<button class="btn btn-default btn-xs" style="float:right" data-toggle="modal" data-target="#nLBA4bBzteJ1obnKYNQ5">
Solution
</button>
<ol start="4" style="list-style-type: decimal">
<li>Decide on which coin to flip next assuming that you exploit.</li>
</ol>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Sutton18" class="csl-entry">
Sutton, R. S., and A. G. Barto. 2018. <em>Reinforcement Learning: An Introduction</em>. Second Edition. MIT Press. <a href="http://incompleteideas.net/book/the-book.html">http://incompleteideas.net/book/the-book.html</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mod-rl-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mod-mdp-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/bss-osca/rl/edit/master/book/02_bandit.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
